{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a303e45c",
      "metadata": {},
      "source": [
        "## Combine Analysis Defensive Tackles \n",
        "\n",
        "Which Combine tests have the most potential influence on a players ability to get drafted and their draft position?\n",
        "\n",
        "Our training dataset is combine data from 2010 - 2020 and our testing dataset is 2021-2024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "0b0a364b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['Year', 'Player', 'Pos', 'School', 'Height', 'Weight', '40yd',\n",
            "       'Vertical', 'Bench', 'Broad Jump', '3Cone', 'Shuttle', 'Drafted',\n",
            "       'Round', 'Pick', 'Sacks_cumulative', 'TFL_cumulative',\n",
            "       'QB_Hurry_cumulative', 'Sacks_final_season', 'TFL_final_season',\n",
            "       'QB_Hurry_final_season'],\n",
            "      dtype='object')\n",
            "Drafted                  1.000000\n",
            "Sacks_final_season       0.537543\n",
            "TFL_final_season         0.471537\n",
            "Sacks_cumulative         0.372802\n",
            "TFL_cumulative           0.224549\n",
            "QB_Hurry_cumulative      0.190996\n",
            "QB_Hurry_final_season    0.183513\n",
            "Bench                    0.167922\n",
            "Broad Jump               0.158607\n",
            "Vertical                 0.141317\n",
            "Weight                   0.127717\n",
            "Height                   0.063890\n",
            "Year                     0.046518\n",
            "Shuttle                 -0.103366\n",
            "3Cone                   -0.109659\n",
            "40yd                    -0.236880\n",
            "Round                         NaN\n",
            "Pick                          NaN\n",
            "Name: Drafted, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "# Path relative to notebook location (DE_similarity_scores_project/) - data is in project root\n",
        "dt_data = pd.read_csv('../data/processed/dt_training_data.csv')\n",
        "print(dt_data.columns)\n",
        "# Convert Height from feet-inches to inches\n",
        "dt_data['Height'] = dt_data['Height'].str.split('-').str[0].astype(int) * 12 + dt_data['Height'].str.split('-').str[1].astype(int)\n",
        "\n",
        "# Examine every column in the dataset and its correlation with the Drafted column \n",
        "dt_data_just_numeric = dt_data.select_dtypes(include=['number'])\n",
        "dt_data_just_numeric['Drafted'] = dt_data['Drafted']\n",
        "print(dt_data_just_numeric.corr()['Drafted'].sort_values(ascending=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "428427ee",
      "metadata": {},
      "source": [
        "For context if the correlation is positive that means that a higher number is better, if a correlation is negative that means that a lower number is better. With that said it looks like our most impactful combine values on **being drafted** are \n",
        "\n",
        "1. Broad Jump: .318\n",
        "2. 40yd: -.311\n",
        "3. Vertical: .266\n",
        "4. Shuttle: -.24\n",
        "5. 3 Cone\n",
        "\n",
        "and our most impactful defensive stats on **being drafted are \n",
        "1. TFL_cumulative           0.486042\n",
        "2. Sacks_cumulative         0.408868\n",
        "3. TFL_final_season         0.396291\n",
        "4. QB_Hurry_cumulative      0.386837\n",
        "5. QB_Hurry_final_season    0.336749\n",
        "6. Sacks_final_season       0.298233\n",
        "\n",
        "Anything too far below abs(.20) is likely too weak to consider using for any models. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "91574611",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pick                     1.000000\n",
            "Round                    0.988804\n",
            "3Cone                    0.108831\n",
            "Year                     0.101440\n",
            "40yd                     0.099456\n",
            "Shuttle                  0.003743\n",
            "TFL_final_season        -0.014431\n",
            "Vertical                -0.020725\n",
            "Height                  -0.034635\n",
            "Weight                  -0.039855\n",
            "TFL_cumulative          -0.047021\n",
            "Broad Jump              -0.057780\n",
            "Bench                   -0.106148\n",
            "Sacks_final_season      -0.212243\n",
            "Sacks_cumulative        -0.302680\n",
            "QB_Hurry_final_season   -0.346735\n",
            "QB_Hurry_cumulative     -0.421125\n",
            "Name: Pick, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Examine every column in the dataset and its correlation with the Drafted column \n",
        "# Lower Draft Position is better\n",
        "dt_data_just_numeric = dt_data.select_dtypes(include=['number'])\n",
        "dt_data_just_numeric['Pick'] = dt_data['Pick']\n",
        "print(dt_data_just_numeric.corr()['Pick'].sort_values(ascending=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af946680",
      "metadata": {},
      "source": [
        "With that said it looks like our most impactful combine values on **Draft Position** are \n",
        "\n",
        "1. 40yd: .338\n",
        "2. Broad Jump: -.228\n",
        "3. 3Cone: .200\n",
        "4. Shuttle \n",
        "\n",
        "It's a little hard to understand what these mean but essentially a higher 40 yard dash and a shorter broad jump correlated with a later round draft pick. So we are looking for shorter 40 yard dashes and longer broad jumps. \n",
        "\n",
        "And it looks like our most impactful defensive values on **Draft Position** are \n",
        "\n",
        "1. TFL_final_season        -0.537341\n",
        "2. Sacks_final_season      -0.463860\n",
        "3. QB_Hurry_final_season   -0.321810"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5ee5cbc",
      "metadata": {},
      "source": [
        "## Looking to Model\n",
        "\n",
        "When we look to create machine learning models there are 3 tasks we would like to accomplish. The first two can use our current datasets of combine data and college data. The final one/two will require the first four seasons of our Defensive Tackles stats in the NFL. \n",
        "\n",
        "1. Projected Drafted or Undrafted\n",
        "2. Projected Draft Position/Round\n",
        "3. Projected NFL Ability/Value "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4d5bd3d",
      "metadata": {},
      "source": [
        "## Projected Drafted or Undrafted\n",
        "\n",
        "We are creating 3 models here to see if a player will be drafted or go undrafted based on their combine and college stats. The training set will be data from 2016 - 2020 and our test set will be 2021-2023. The three models we will be testing will be ordinal logistic regression, random tree and XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "6165e69a",
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train_2017' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[22], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m COLLEGE_ONLY_CONTAINS \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontains_qb_hurry_final_season\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontains_tfl_final_season\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontains_sacks_final_season\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontains_sacks_cumulative\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontains_tfl_cumulative\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontains_qb_hurry_cumulative\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontains_p4_conference\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontains_height\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontains_weight\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      7\u001b[0m COLLEGE_ONLY_ALL \u001b[38;5;241m=\u001b[39m COLLEGE_ONLY_FEATURES \u001b[38;5;241m+\u001b[39m COLLEGE_ONLY_CONTAINS\n\u001b[0;32m----> 9\u001b[0m X_tr_co \u001b[38;5;241m=\u001b[39m train_2017[COLLEGE_ONLY_ALL]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     10\u001b[0m X_te_co \u001b[38;5;241m=\u001b[39m test_2017[COLLEGE_ONLY_ALL]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     11\u001b[0m train_medians_co \u001b[38;5;241m=\u001b[39m X_tr_co\u001b[38;5;241m.\u001b[39mmedian()\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_2017' is not defined"
          ]
        }
      ],
      "source": [
        "# College-only models: QB Hurry, TFL, Sacks + p4_conference (and cumulative) only (no combine metrics)\n",
        "# For players without combine data (e.g. 2026 prospects pre-combine)\n",
        "# DT includes cumulative stats like edges\n",
        "\n",
        "COLLEGE_ONLY_FEATURES = ['QB_Hurry_final_season', 'TFL_final_season', 'Sacks_final_season', 'Sacks_cumulative', 'TFL_cumulative', 'QB_Hurry_cumulative', 'p4_conference', 'Height', 'Weight']\n",
        "COLLEGE_ONLY_CONTAINS = ['contains_qb_hurry_final_season', 'contains_tfl_final_season', 'contains_sacks_final_season', 'contains_sacks_cumulative', 'contains_tfl_cumulative', 'contains_qb_hurry_cumulative', 'contains_p4_conference', 'contains_height', 'contains_weight']\n",
        "COLLEGE_ONLY_ALL = COLLEGE_ONLY_FEATURES + COLLEGE_ONLY_CONTAINS\n",
        "\n",
        "X_tr_co = train_2017[COLLEGE_ONLY_ALL].copy()\n",
        "X_te_co = test_2017[COLLEGE_ONLY_ALL].copy()\n",
        "train_medians_co = X_tr_co.median()\n",
        "X_tr_co = X_tr_co.fillna(train_medians_co)\n",
        "X_te_co = X_te_co.fillna(train_medians_co)\n",
        "\n",
        "scaler_co = StandardScaler()\n",
        "X_tr_co_scaled = scaler_co.fit_transform(X_tr_co)\n",
        "X_te_co_scaled = scaler_co.transform(X_te_co)\n",
        "\n",
        "logit_draft_college_only = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')\n",
        "logit_draft_college_only.fit(X_tr_co_scaled, y_train17)\n",
        "y_pred_college_only = logit_draft_college_only.predict(X_te_co_scaled)\n",
        "y_prob_college_only = logit_draft_college_only.predict_proba(X_te_co_scaled)[:, 1]\n",
        "\n",
        "rf_college_only = RandomForestClassifier(n_estimators=200, max_depth=6, random_state=42, class_weight='balanced')\n",
        "rf_college_only.fit(X_tr_co, y_train17)\n",
        "y_pred_rf_co = rf_college_only.predict(X_te_co)\n",
        "y_prob_rf_co = rf_college_only.predict_proba(X_te_co)[:, 1]\n",
        "\n",
        "xgb_college_only = xgb.XGBClassifier(n_estimators=200, max_depth=4, learning_rate=0.1, random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
        "xgb_college_only.fit(X_tr_co, y_train17)\n",
        "y_pred_xgb_co = xgb_college_only.predict(X_te_co)\n",
        "y_prob_xgb_co = xgb_college_only.predict_proba(X_te_co)[:, 1]\n",
        "\n",
        "print('College-only models (QB Hurry, TFL, Sacks, cumulative, p4_conference) — drafted/undrafted')\n",
        "print('=' * 75)\n",
        "for name, pred, prob in [('Logistic', y_pred_college_only, y_prob_college_only), ('RF', y_pred_rf_co, y_prob_rf_co), ('XGB', y_pred_xgb_co, y_prob_xgb_co)]:\n",
        "    print(f'{name}: accuracy={(pred == y_test17).mean():.4f}, ROC-AUC={roc_auc_score(y_test17, prob):.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2183ca00",
      "metadata": {},
      "outputs": [],
      "source": [
        "# College + combine with agility: train on players with 3Cone+Shuttle (agility_score present)\n",
        "# Use agility models when player has agility_score; otherwise use non-agility\n",
        "FEATURES_WITH_COLLEGE_AGILITY = FEATURES_WITH_COLLEGE + ['agility_score']\n",
        "CONTAINS_WITH_COLLEGE_AGILITY = CONTAINS_WITH_COLLEGE + ['contains_agility_score']\n",
        "FEATURES_WITH_COLLEGE_AGILITY_ALL = FEATURES_WITH_COLLEGE_AGILITY + CONTAINS_WITH_COLLEGE_AGILITY\n",
        "\n",
        "has_agility_train = train_2017['3Cone'].notna() & train_2017['Shuttle'].notna()\n",
        "train_agility = train_2017[has_agility_train]\n",
        "X_tr_ag = train_agility[FEATURES_WITH_COLLEGE_AGILITY_ALL].copy()\n",
        "train_medians_ag = X_tr_ag.median()\n",
        "X_tr_ag = X_tr_ag.fillna(train_medians_ag)\n",
        "scaler_ag = StandardScaler()\n",
        "X_tr_ag_scaled = scaler_ag.fit_transform(X_tr_ag)\n",
        "y_train_ag = (train_agility['Drafted'].astype(bool)).astype(int)\n",
        "\n",
        "logit_draft_college_agility = LogisticRegression(max_iter=1000, random_state=42)\n",
        "logit_draft_college_agility.fit(X_tr_ag_scaled, y_train_ag)\n",
        "rf_college_agility = RandomForestClassifier(n_estimators=200, max_depth=7, random_state=42)\n",
        "rf_college_agility.fit(X_tr_ag, y_train_ag)\n",
        "xgb_college_agility = xgb.XGBClassifier(n_estimators=200, max_depth=4, learning_rate=0.1, random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
        "xgb_college_agility.fit(X_tr_ag, y_train_ag)\n",
        "\n",
        "# Predict on full test (impute missing agility with median)\n",
        "X_te_ag_fill = test_2017[FEATURES_WITH_COLLEGE_AGILITY_ALL].copy().fillna(train_medians_ag)\n",
        "X_te_ag_fill_scaled = scaler_ag.transform(X_te_ag_fill)\n",
        "y_pred_agility = logit_draft_college_agility.predict(X_te_ag_fill_scaled)\n",
        "y_prob_agility = logit_draft_college_agility.predict_proba(X_te_ag_fill_scaled)[:, 1]\n",
        "y_pred_rf_agility = rf_college_agility.predict(X_te_ag_fill)\n",
        "y_prob_rf_agility = rf_college_agility.predict_proba(X_te_ag_fill)[:, 1]\n",
        "y_pred_xgb_agility = xgb_college_agility.predict(X_te_ag_fill)\n",
        "y_prob_xgb_agility = xgb_college_agility.predict_proba(X_te_ag_fill)[:, 1]\n",
        "\n",
        "print('College+combine w/ agility: trained on', len(train_agility), 'players with 3Cone+Shuttle')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a0a9292",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set: 231 players\n",
            "Test set: 54 players\n",
            "\n",
            "Modeling features: ['Broad Jump', 'Vertical', 'QB_Hurry_final_season', 'TFL_final_season', 'Sacks_final_season', 'Shuttle', '3Cone', '40yd', 'Height', 'Weight']\n",
            "Derived metrics: speed_score, explosive_score, agility_score\n",
            "Contains flags: contains_* for each metric\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Player</th>\n",
              "      <th>Pos</th>\n",
              "      <th>School</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>40yd</th>\n",
              "      <th>Vertical</th>\n",
              "      <th>Bench</th>\n",
              "      <th>Broad Jump</th>\n",
              "      <th>...</th>\n",
              "      <th>contains_three_cone</th>\n",
              "      <th>contains_40yd</th>\n",
              "      <th>contains_height</th>\n",
              "      <th>contains_weight</th>\n",
              "      <th>contains_speed_score</th>\n",
              "      <th>contains_explosive_score</th>\n",
              "      <th>contains_agility_score</th>\n",
              "      <th>contains_sacks_cumulative</th>\n",
              "      <th>contains_tfl_cumulative</th>\n",
              "      <th>contains_qb_hurry_cumulative</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010</td>\n",
              "      <td>Charles Alexander</td>\n",
              "      <td>DT</td>\n",
              "      <td>LSU</td>\n",
              "      <td>76</td>\n",
              "      <td>300.0</td>\n",
              "      <td>5.40</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010</td>\n",
              "      <td>Geno Atkins</td>\n",
              "      <td>DT</td>\n",
              "      <td>Georgia</td>\n",
              "      <td>73</td>\n",
              "      <td>293.0</td>\n",
              "      <td>4.75</td>\n",
              "      <td>33.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2010</td>\n",
              "      <td>Terrence Cody</td>\n",
              "      <td>DT</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>76</td>\n",
              "      <td>354.0</td>\n",
              "      <td>5.71</td>\n",
              "      <td>20.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>90.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010</td>\n",
              "      <td>Brandon Deaderick</td>\n",
              "      <td>DT</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>76</td>\n",
              "      <td>314.0</td>\n",
              "      <td>5.08</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2010</td>\n",
              "      <td>Lamarr Houston</td>\n",
              "      <td>DT</td>\n",
              "      <td>Texas</td>\n",
              "      <td>75</td>\n",
              "      <td>305.0</td>\n",
              "      <td>4.84</td>\n",
              "      <td>33.5</td>\n",
              "      <td>30.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 40 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Year             Player Pos   School  Height  Weight  40yd  Vertical  \\\n",
              "0  2010  Charles Alexander  DT      LSU      76   300.0  5.40       NaN   \n",
              "1  2010        Geno Atkins  DT  Georgia      73   293.0  4.75      33.0   \n",
              "2  2010      Terrence Cody  DT  Alabama      76   354.0  5.71      20.5   \n",
              "3  2010  Brandon Deaderick  DT  Alabama      76   314.0  5.08       NaN   \n",
              "4  2010     Lamarr Houston  DT    Texas      75   305.0  4.84      33.5   \n",
              "\n",
              "   Bench  Broad Jump  ...  contains_three_cone  contains_40yd  \\\n",
              "0    NaN         NaN  ...                    0              1   \n",
              "1   34.0       117.0  ...                    1              1   \n",
              "2    NaN        90.0  ...                    1              1   \n",
              "3    NaN         NaN  ...                    0              1   \n",
              "4   30.0       114.0  ...                    1              1   \n",
              "\n",
              "   contains_height  contains_weight  contains_speed_score  \\\n",
              "0                1                1                     1   \n",
              "1                1                1                     1   \n",
              "2                1                1                     1   \n",
              "3                1                1                     1   \n",
              "4                1                1                     1   \n",
              "\n",
              "   contains_explosive_score  contains_agility_score  \\\n",
              "0                         1                       1   \n",
              "1                         1                       1   \n",
              "2                         1                       1   \n",
              "3                         1                       1   \n",
              "4                         1                       1   \n",
              "\n",
              "   contains_sacks_cumulative  contains_tfl_cumulative  \\\n",
              "0                          0                        0   \n",
              "1                          0                        0   \n",
              "2                          0                        0   \n",
              "3                          0                        0   \n",
              "4                          0                        0   \n",
              "\n",
              "   contains_qb_hurry_cumulative  \n",
              "0                             0  \n",
              "1                             0  \n",
              "2                             0  \n",
              "3                             0  \n",
              "4                             0  \n",
              "\n",
              "[5 rows x 40 columns]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load training and testing data (paths relative to DT/)\n",
        "train_raw = pd.read_csv('../data/processed/dt_training_data.csv')\n",
        "test_raw = pd.read_csv('../data/processed/dt_testing_data.csv')\n",
        "\n",
        "# Convert Height from feet-inches to inches\n",
        "def height_to_inches(h):\n",
        "    if pd.isna(h) or not isinstance(h, str) or '-' not in str(h):\n",
        "        return np.nan\n",
        "    parts = str(h).split('-')\n",
        "    return int(parts[0]) * 12 + int(parts[1])\n",
        "\n",
        "for df in [train_raw, test_raw]:\n",
        "    df['Height'] = df['Height'].apply(height_to_inches)\n",
        "\n",
        "# Column names for modeling (match CSV)\n",
        "FEATURE_COLS = [\n",
        "    'Broad Jump', 'Vertical', 'QB_Hurry_final_season', 'TFL_final_season',\n",
        "    'Sacks_final_season', 'Shuttle', '3Cone', '40yd', 'Height', 'Weight'\n",
        "]\n",
        "\n",
        "# --- Speed Score: weight * 200 / 40yd^4 ---\n",
        "def add_speed_score(df):\n",
        "    df = df.copy()\n",
        "    df['speed_score'] = np.where(\n",
        "        df['40yd'].notna() & (df['40yd'] > 0),\n",
        "        df['Weight'] * 200 / (df['40yd'] ** 4),\n",
        "        np.nan\n",
        "    )\n",
        "    return df\n",
        "\n",
        "train_raw = add_speed_score(train_raw)\n",
        "test_raw = add_speed_score(test_raw)\n",
        "\n",
        "# --- Explosive Score (position-specific z-scores from training data) ---\n",
        "def add_explosive_score(train_df, test_df):\n",
        "    train_df = train_df.copy()\n",
        "    test_df = test_df.copy()\n",
        "    train_df['vertical_z'] = np.nan\n",
        "    train_df['broad_z'] = np.nan\n",
        "    test_df['vertical_z'] = np.nan\n",
        "    test_df['broad_z'] = np.nan\n",
        "    for pos in train_df['Pos'].dropna().unique():\n",
        "        tr = train_df[train_df['Pos'] == pos]\n",
        "        mean_v = tr['Vertical'].mean()\n",
        "        std_v = tr['Vertical'].std()\n",
        "        mean_b = tr['Broad Jump'].mean()\n",
        "        std_b = tr['Broad Jump'].std()\n",
        "        if std_v == 0 or np.isnan(std_v):\n",
        "            std_v = 1.0\n",
        "        if std_b == 0 or np.isnan(std_b):\n",
        "            std_b = 1.0\n",
        "        mask_train = train_df['Pos'] == pos\n",
        "        mask_test = test_df['Pos'] == pos\n",
        "        train_df.loc[mask_train, 'vertical_z'] = (train_df.loc[mask_train, 'Vertical'] - mean_v) / std_v\n",
        "        train_df.loc[mask_train, 'broad_z'] = (train_df.loc[mask_train, 'Broad Jump'] - mean_b) / std_b\n",
        "        test_df.loc[mask_test, 'vertical_z'] = (test_df.loc[mask_test, 'Vertical'] - mean_v) / std_v\n",
        "        test_df.loc[mask_test, 'broad_z'] = (test_df.loc[mask_test, 'Broad Jump'] - mean_b) / std_b\n",
        "    train_df['explosive_score'] = train_df['vertical_z'].fillna(0) + train_df['broad_z'].fillna(0)\n",
        "    test_df['explosive_score'] = test_df['vertical_z'].fillna(0) + test_df['broad_z'].fillna(0)\n",
        "    return train_df.drop(columns=['vertical_z', 'broad_z'], errors='ignore'), test_df.drop(columns=['vertical_z', 'broad_z'], errors='ignore')\n",
        "\n",
        "train_raw, test_raw = add_explosive_score(train_raw, test_raw)\n",
        "\n",
        "# --- Agility Score (position-specific z-scores from training; flip sign so better = higher) ---\n",
        "def add_agility_score(train_df, test_df):\n",
        "    train_df = train_df.copy()\n",
        "    test_df = test_df.copy()\n",
        "    train_df['three_cone_z'] = np.nan\n",
        "    train_df['shuttle_z'] = np.nan\n",
        "    test_df['three_cone_z'] = np.nan\n",
        "    test_df['shuttle_z'] = np.nan\n",
        "    for pos in train_df['Pos'].dropna().unique():\n",
        "        tr = train_df[train_df['Pos'] == pos]\n",
        "        mean_3 = tr['3Cone'].mean()\n",
        "        std_3 = tr['3Cone'].std()\n",
        "        mean_sh = tr['Shuttle'].mean()\n",
        "        std_sh = tr['Shuttle'].std()\n",
        "        if std_3 == 0 or np.isnan(std_3):\n",
        "            std_3 = 1.0\n",
        "        if std_sh == 0 or np.isnan(std_sh):\n",
        "            std_sh = 1.0\n",
        "        mask_train = train_df['Pos'] == pos\n",
        "        mask_test = test_df['Pos'] == pos\n",
        "        train_df.loc[mask_train, 'three_cone_z'] = (train_df.loc[mask_train, '3Cone'] - mean_3) / std_3\n",
        "        train_df.loc[mask_train, 'shuttle_z'] = (train_df.loc[mask_train, 'Shuttle'] - mean_sh) / std_sh\n",
        "        test_df.loc[mask_test, 'three_cone_z'] = (test_df.loc[mask_test, '3Cone'] - mean_3) / std_3\n",
        "        test_df.loc[mask_test, 'shuttle_z'] = (test_df.loc[mask_test, 'Shuttle'] - mean_sh) / std_sh\n",
        "    train_df['agility_score'] = (-train_df['three_cone_z'].fillna(0)) + (-train_df['shuttle_z'].fillna(0))\n",
        "    test_df['agility_score'] = (-test_df['three_cone_z'].fillna(0)) + (-test_df['shuttle_z'].fillna(0))\n",
        "    return train_df.drop(columns=['three_cone_z', 'shuttle_z'], errors='ignore'), test_df.drop(columns=['three_cone_z', 'shuttle_z'], errors='ignore')\n",
        "\n",
        "train_raw, test_raw = add_agility_score(train_raw, test_raw)\n",
        "\n",
        "# --- P4 conference: binary 1 if School in power conference. Pac-12 counts only for draft year 2023 and before. ---\n",
        "P4_WITH_PAC12 = {'SEC', 'Big Ten', 'Big 12', 'ACC', 'Pac-12'}\n",
        "P4_NO_PAC12 = {'SEC', 'Big Ten', 'Big 12', 'ACC'}\n",
        "_stats = pd.read_csv('../data/processed/defensive_stats_2016_to_2025.csv')\n",
        "P4_SCHOOLS = set(_stats[_stats['Conference'].isin(P4_WITH_PAC12)]['Team'].unique())\n",
        "P4_SCHOOLS_NO_PAC12 = set(_stats[_stats['Conference'].isin(P4_NO_PAC12)]['Team'].unique())\n",
        "school_alias = {\n",
        "    'Ole Miss': 'Mississippi', 'Miami (FL)': 'Miami', 'Southern California': 'USC',\n",
        "    'Central Florida': 'UCF', 'Brigham Young': 'BYU', 'Ohio St.': 'Ohio State',\n",
        "    'Florida St.': 'Florida State', 'Kansas St.': 'Kansas State', 'Iowa St.': 'Iowa State',\n",
        "    'Oklahoma St.': 'Oklahoma State', 'Penn St.': 'Penn State', 'San Diego St.': 'San Diego State',\n",
        "    'San Jose St.': 'San José State', 'Boston Col.': 'Boston College',\n",
        "}\n",
        "\n",
        "def add_p4_conference(df):\n",
        "    df = df.copy()\n",
        "    def norm(s):\n",
        "        return school_alias.get(s, s) if pd.notna(s) and s else None\n",
        "    def is_p4(row):\n",
        "        sn = norm(row['School'])\n",
        "        if not sn: return 0\n",
        "        year = row.get('Year', 0)\n",
        "        schools = P4_SCHOOLS if year <= 2023 else P4_SCHOOLS_NO_PAC12\n",
        "        return 1 if sn in schools else 0\n",
        "    df['p4_conference'] = df.apply(is_p4, axis=1)\n",
        "    df['contains_p4_conference'] = df['School'].notna().astype(int)\n",
        "    return df\n",
        "\n",
        "train_raw = add_p4_conference(train_raw)\n",
        "test_raw = add_p4_conference(test_raw)\n",
        "\n",
        "# --- Binary contains_* for each metric (1 if present, 0 if missing) ---\n",
        "METRIC_COLS = [\n",
        "    'Broad Jump', 'Vertical', 'QB_Hurry_final_season', 'TFL_final_season',\n",
        "    'Sacks_final_season', 'Shuttle', '3Cone', '40yd', 'Height', 'Weight',\n",
        "    'speed_score', 'explosive_score', 'agility_score',\n",
        "    'Sacks_cumulative', 'TFL_cumulative', 'QB_Hurry_cumulative'\n",
        "]\n",
        "def add_contains_flags(df):\n",
        "    df = df.copy()\n",
        "    name_map = {\n",
        "        'Broad Jump': 'broad_jump', 'Vertical': 'vertical',\n",
        "        'QB_Hurry_final_season': 'qb_hurry_final_season', 'TFL_final_season': 'tfl_final_season',\n",
        "        'Sacks_final_season': 'sacks_final_season', 'Sacks_cumulative': 'sacks_cumulative', 'TFL_cumulative': 'tfl_cumulative', 'QB_Hurry_cumulative': 'qb_hurry_cumulative',\n",
        "        'Shuttle': 'shuttle', '3Cone': 'three_cone',\n",
        "        '40yd': '40yd', 'Height': 'height', 'Weight': 'weight',\n",
        "        'speed_score': 'speed_score', 'explosive_score': 'explosive_score', 'agility_score': 'agility_score'\n",
        "    }\n",
        "    for col in METRIC_COLS:\n",
        "        if col not in df.columns:\n",
        "            continue\n",
        "        flag_name = f\"contains_{name_map.get(col, col.lower().replace(' ', '_'))}\"\n",
        "        df[flag_name] = (df[col].notna()).astype(int)\n",
        "    return df\n",
        "\n",
        "train_raw = add_contains_flags(train_raw)\n",
        "test_raw = add_contains_flags(test_raw)\n",
        "\n",
        "# Final training and test datasets for modeling\n",
        "train_df = train_raw.copy()\n",
        "test_df = test_raw.copy()\n",
        "\n",
        "print('Training set:', train_df.shape[0], 'players')\n",
        "print('Test set:', test_df.shape[0], 'players')\n",
        "print('\\nModeling features:', FEATURE_COLS)\n",
        "print('Derived metrics: speed_score, explosive_score, agility_score')\n",
        "print('Contains flags: contains_* for each metric')\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f124a09",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combine-only logistic model: Drafted vs Undrafted\n",
            "==================================================\n",
            "Test accuracy: 0.7407\n",
            "\n",
            "Confusion matrix (rows=actual, cols=predicted):\n",
            "[[ 8 13]\n",
            " [ 1 32]]\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Undrafted       0.89      0.38      0.53        21\n",
            "     Drafted       0.71      0.97      0.82        33\n",
            "\n",
            "    accuracy                           0.74        54\n",
            "   macro avg       0.80      0.68      0.68        54\n",
            "weighted avg       0.78      0.74      0.71        54\n",
            "\n",
            "Test ROC-AUC: 0.8355\n"
          ]
        }
      ],
      "source": [
        "# Combine-only logistic regression: predict Drafted (1) vs Undrafted (0)\n",
        "# No college stats — only combine metrics + derived scores\n",
        "\n",
        "# Combine-only features (no Sacks/TFL/QB Hurry) + binary \"contains_*\" flags\n",
        "# Exclude Shuttle, 3Cone, agility_score — often missing at combine\n",
        "COMBINE_ONLY_FEATURES = [\n",
        "    'Broad Jump', 'Vertical', '40yd', 'Height', 'Weight',\n",
        "    'speed_score', 'explosive_score', 'p4_conference'\n",
        "]\n",
        "COMBINE_ONLY_CONTAINS = [\n",
        "    'contains_broad_jump', 'contains_vertical',\n",
        "    'contains_40yd', 'contains_height', 'contains_weight',\n",
        "    'contains_speed_score', 'contains_explosive_score', 'contains_p4_conference'\n",
        "]\n",
        "COMBINE_ONLY_ALL = COMBINE_ONLY_FEATURES + COMBINE_ONLY_CONTAINS\n",
        "\n",
        "# Prepare X, y\n",
        "X_tr = train_df[COMBINE_ONLY_ALL].copy()\n",
        "X_te = test_df[COMBINE_ONLY_ALL].copy()\n",
        "y_train = (train_df['Drafted'].astype(bool)).astype(int)\n",
        "y_test = (test_df['Drafted'].astype(bool)).astype(int)\n",
        "\n",
        "# Impute missing with training medians\n",
        "train_medians = X_tr.median()\n",
        "X_tr = X_tr.fillna(train_medians)\n",
        "X_te = X_te.fillna(train_medians)\n",
        "\n",
        "# Scale (fit on train, transform both)\n",
        "scaler = StandardScaler()\n",
        "X_tr_scaled = scaler.fit_transform(X_tr)\n",
        "X_te_scaled = scaler.transform(X_te)\n",
        "\n",
        "# Fit binary logistic regression\n",
        "logit_draft = LogisticRegression(max_iter=1000, random_state=42)\n",
        "logit_draft.fit(X_tr_scaled, y_train)\n",
        "\n",
        "# Predict on test\n",
        "y_pred = logit_draft.predict(X_te_scaled)\n",
        "y_prob = logit_draft.predict_proba(X_te_scaled)[:, 1]\n",
        "\n",
        "# Metrics\n",
        "print('Combine-only logistic model: Drafted vs Undrafted')\n",
        "print('=' * 50)\n",
        "print('Test accuracy:', (y_pred == y_test).mean().round(4))\n",
        "print('\\nConfusion matrix (rows=actual, cols=predicted):')\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print('\\nClassification report:')\n",
        "print(classification_report(y_test, y_pred, target_names=['Undrafted', 'Drafted']))\n",
        "if y_test.nunique() == 2:\n",
        "    print('Test ROC-AUC:', roc_auc_score(y_test, y_prob).round(4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0717e7c2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic model with college stats (train 2017+, test 2017+)\n",
            "=======================================================\n",
            "Training samples: 46 | Test samples: 54\n",
            "Test accuracy: 0.7407\n",
            "\n",
            "Confusion matrix (rows=actual, cols=predicted):\n",
            "[[13  8]\n",
            " [ 6 27]]\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Undrafted       0.68      0.62      0.65        21\n",
            "     Drafted       0.77      0.82      0.79        33\n",
            "\n",
            "    accuracy                           0.74        54\n",
            "   macro avg       0.73      0.72      0.72        54\n",
            "weighted avg       0.74      0.74      0.74        54\n",
            "\n",
            "Test ROC-AUC: 0.8384\n"
          ]
        }
      ],
      "source": [
        "# Logistic regression with college stats: training data from 2017 onward\n",
        "# Same target (Drafted vs Undrafted), with combine + college stats\n",
        "\n",
        "# Restrict to 2017+ so college stats are available\n",
        "train_2017 = train_df[train_df['Year'] >= 2017].copy()\n",
        "test_2017 = test_df[test_df['Year'] >= 2017].copy()\n",
        "\n",
        "# Full feature set (combine + college stats) + binary \"contains_*\" flags\n",
        "# Exclude Shuttle, 3Cone, agility_score — often missing; keep cumulative stats (DT-specific)\n",
        "FEATURES_WITH_COLLEGE = [\n",
        "    'Broad Jump', 'Vertical', '40yd', 'Height', 'Weight',\n",
        "    'speed_score', 'explosive_score',\n",
        "    'QB_Hurry_final_season', 'TFL_final_season', 'Sacks_final_season',\n",
        "    'Sacks_cumulative', 'TFL_cumulative', 'QB_Hurry_cumulative', 'p4_conference'\n",
        "]\n",
        "CONTAINS_WITH_COLLEGE = [\n",
        "    'contains_broad_jump', 'contains_vertical',\n",
        "    'contains_40yd', 'contains_height', 'contains_weight',\n",
        "    'contains_speed_score', 'contains_explosive_score',\n",
        "    'contains_qb_hurry_final_season', 'contains_tfl_final_season', 'contains_sacks_final_season',\n",
        "    'contains_sacks_cumulative', 'contains_tfl_cumulative', 'contains_qb_hurry_cumulative',\n",
        "    'contains_p4_conference'\n",
        "]\n",
        "FEATURES_WITH_COLLEGE_ALL = FEATURES_WITH_COLLEGE + CONTAINS_WITH_COLLEGE\n",
        "\n",
        "X_tr17 = train_2017[FEATURES_WITH_COLLEGE_ALL].copy()\n",
        "X_te17 = test_2017[FEATURES_WITH_COLLEGE_ALL].copy()\n",
        "y_train17 = (train_2017['Drafted'].astype(bool)).astype(int)\n",
        "y_test17 = (test_2017['Drafted'].astype(bool)).astype(int)\n",
        "\n",
        "# Impute missing with training medians\n",
        "train_medians17 = X_tr17.median()\n",
        "X_tr17 = X_tr17.fillna(train_medians17)\n",
        "X_te17 = X_te17.fillna(train_medians17)\n",
        "\n",
        "# Scale (fit on train, transform both)\n",
        "scaler17 = StandardScaler()\n",
        "X_tr17_scaled = scaler17.fit_transform(X_tr17)\n",
        "X_te17_scaled = scaler17.transform(X_te17)\n",
        "\n",
        "# Fit logistic regression (with college stats)\n",
        "logit_draft_college = LogisticRegression(max_iter=1000, random_state=42)\n",
        "logit_draft_college.fit(X_tr17_scaled, y_train17)\n",
        "\n",
        "y_pred17 = logit_draft_college.predict(X_te17_scaled)\n",
        "y_prob17 = logit_draft_college.predict_proba(X_te17_scaled)[:, 1]\n",
        "\n",
        "print('Logistic model with college stats (train 2017+, test 2017+)')\n",
        "print('=' * 55)\n",
        "print('Training samples:', len(train_2017), '| Test samples:', len(test_2017))\n",
        "print('Test accuracy:', (y_pred17 == y_test17).mean().round(4))\n",
        "print('\\nConfusion matrix (rows=actual, cols=predicted):')\n",
        "print(confusion_matrix(y_test17, y_pred17))\n",
        "print('\\nClassification report:')\n",
        "print(classification_report(y_test17, y_pred17, target_names=['Undrafted', 'Drafted']))\n",
        "if y_test17.nunique() == 2 and len(y_test17) > 0:\n",
        "    print('Test ROC-AUC:', roc_auc_score(y_test17, y_prob17).round(4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "487f40b1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combined model: average of combine-only + college-stats probabilities\n",
            "============================================================\n",
            "Test accuracy: 0.8519\n",
            "\n",
            "Confusion matrix (rows=actual, cols=predicted):\n",
            "[[13  8]\n",
            " [ 0 33]]\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Undrafted       1.00      0.62      0.76        21\n",
            "     Drafted       0.80      1.00      0.89        33\n",
            "\n",
            "    accuracy                           0.85        54\n",
            "   macro avg       0.90      0.81      0.83        54\n",
            "weighted avg       0.88      0.85      0.84        54\n",
            "\n",
            "Test ROC-AUC: 0.8644\n"
          ]
        }
      ],
      "source": [
        "# Combined prediction: average both models' probabilities into one drafted/undrafted prediction\n",
        "# Combine-only model predicts on full test_df; college model on test_2017 (2017+). Test set is 2021+ so both apply to all rows.\n",
        "\n",
        "combined_prob = (y_prob + y_prob17) / 2\n",
        "combined_pred = (combined_prob >= 0.5).astype(int)\n",
        "\n",
        "# Use same test labels (y_test from full test_df; same rows as test_2017)\n",
        "print('Combined model: average of combine-only + college-stats probabilities')\n",
        "print('=' * 60)\n",
        "print('Test accuracy:', (combined_pred == y_test).mean().round(4))\n",
        "print('\\nConfusion matrix (rows=actual, cols=predicted):')\n",
        "print(confusion_matrix(y_test, combined_pred))\n",
        "print('\\nClassification report:')\n",
        "print(classification_report(y_test, combined_pred, target_names=['Undrafted', 'Drafted']))\n",
        "print('Test ROC-AUC:', roc_auc_score(y_test, combined_prob).round(4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de9fd364",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest (combine-only): Drafted vs Undrafted\n",
            "=======================================================\n",
            "Test accuracy: 0.7407\n",
            "\n",
            "Confusion matrix (rows=actual, cols=predicted):\n",
            "[[ 9 12]\n",
            " [ 2 31]]\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Undrafted       0.82      0.43      0.56        21\n",
            "     Drafted       0.72      0.94      0.82        33\n",
            "\n",
            "    accuracy                           0.74        54\n",
            "   macro avg       0.77      0.68      0.69        54\n",
            "weighted avg       0.76      0.74      0.72        54\n",
            "\n",
            "Test ROC-AUC: 0.8211\n"
          ]
        }
      ],
      "source": [
        "# Random Forest: combine-only features — predict Drafted vs Undrafted\n",
        "\n",
        "rf_combine = RandomForestClassifier(n_estimators=200, max_depth=9, random_state=42)\n",
        "rf_combine.fit(X_tr, y_train)  # X_tr already has COMBINE_ONLY_ALL, imputed\n",
        "\n",
        "y_pred_rf = rf_combine.predict(X_te)\n",
        "y_prob_rf = rf_combine.predict_proba(X_te)[:, 1]\n",
        "\n",
        "print('Random Forest (combine-only): Drafted vs Undrafted')\n",
        "print('=' * 55)\n",
        "print('Test accuracy:', (y_pred_rf == y_test).mean().round(4))\n",
        "print('\\nConfusion matrix (rows=actual, cols=predicted):')\n",
        "print(confusion_matrix(y_test, y_pred_rf))\n",
        "print('\\nClassification report:')\n",
        "print(classification_report(y_test, y_pred_rf, target_names=['Undrafted', 'Drafted']))\n",
        "print('Test ROC-AUC:', roc_auc_score(y_test, y_prob_rf).round(4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb321a6b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest (combine + college, train 2017+): Drafted vs Undrafted\n",
            "============================================================\n",
            "Training samples: 46 | Test samples: 54\n",
            "Test accuracy: 0.7037\n",
            "\n",
            "Confusion matrix (rows=actual, cols=predicted):\n",
            "[[ 9 12]\n",
            " [ 4 29]]\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Undrafted       0.69      0.43      0.53        21\n",
            "     Drafted       0.71      0.88      0.78        33\n",
            "\n",
            "    accuracy                           0.70        54\n",
            "   macro avg       0.70      0.65      0.66        54\n",
            "weighted avg       0.70      0.70      0.68        54\n",
            "\n",
            "Test ROC-AUC: 0.746\n"
          ]
        }
      ],
      "source": [
        "# Random Forest: combine + college stats (2017+)\n",
        "rf_college = RandomForestClassifier(n_estimators=200, max_depth=7, random_state=42)\n",
        "rf_college.fit(X_tr17, y_train17)  # X_tr17 already has FEATURES_WITH_COLLEGE_ALL, imputed\n",
        "\n",
        "y_pred_rf17 = rf_college.predict(X_te17)\n",
        "y_prob_rf17 = rf_college.predict_proba(X_te17)[:, 1]\n",
        "\n",
        "print('Random Forest (combine + college, train 2017+): Drafted vs Undrafted')\n",
        "print('=' * 60)\n",
        "print('Training samples:', len(train_2017), '| Test samples:', len(test_2017))\n",
        "print('Test accuracy:', (y_pred_rf17 == y_test17).mean().round(4))\n",
        "print('\\nConfusion matrix (rows=actual, cols=predicted):')\n",
        "print(confusion_matrix(y_test17, y_pred_rf17))\n",
        "print('\\nClassification report:')\n",
        "print(classification_report(y_test17, y_pred_rf17, target_names=['Undrafted', 'Drafted']))\n",
        "print('Test ROC-AUC:', roc_auc_score(y_test17, y_prob_rf17).round(4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6376426",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combined Random Forest: average of combine-only + college-stats probabilities\n",
            "=================================================================\n",
            "Test accuracy: 0.7037\n",
            "\n",
            "Confusion matrix (rows=actual, cols=predicted):\n",
            "[[ 6 15]\n",
            " [ 1 32]]\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Undrafted       0.86      0.29      0.43        21\n",
            "     Drafted       0.68      0.97      0.80        33\n",
            "\n",
            "    accuracy                           0.70        54\n",
            "   macro avg       0.77      0.63      0.61        54\n",
            "weighted avg       0.75      0.70      0.66        54\n",
            "\n",
            "Test ROC-AUC: 0.8211\n"
          ]
        }
      ],
      "source": [
        "# Combined RF prediction: average both RF models' probabilities\n",
        "combined_prob_rf = (y_prob_rf + y_prob_rf17) / 2\n",
        "combined_pred_rf = (combined_prob_rf >= 0.5).astype(int)\n",
        "\n",
        "print('Combined Random Forest: average of combine-only + college-stats probabilities')\n",
        "print('=' * 65)\n",
        "print('Test accuracy:', (combined_pred_rf == y_test).mean().round(4))\n",
        "print('\\nConfusion matrix (rows=actual, cols=predicted):')\n",
        "print(confusion_matrix(y_test, combined_pred_rf))\n",
        "print('\\nClassification report:')\n",
        "print(classification_report(y_test, combined_pred_rf, target_names=['Undrafted', 'Drafted']))\n",
        "print('Test ROC-AUC:', roc_auc_score(y_test, combined_prob_rf).round(4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7dc89e9c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost (combine-only): Drafted vs Undrafted\n",
            "=======================================================\n",
            "Test accuracy: 0.7778\n",
            "\n",
            "Confusion matrix (rows=actual, cols=predicted):\n",
            "[[10 11]\n",
            " [ 1 32]]\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Undrafted       0.91      0.48      0.62        21\n",
            "     Drafted       0.74      0.97      0.84        33\n",
            "\n",
            "    accuracy                           0.78        54\n",
            "   macro avg       0.83      0.72      0.73        54\n",
            "weighted avg       0.81      0.78      0.76        54\n",
            "\n",
            "Test ROC-AUC: 0.7937\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [16:53:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        }
      ],
      "source": [
        "# XGBoost: combine-only features — predict Drafted vs Undrafted\n",
        "\n",
        "xgb_combine = xgb.XGBClassifier(n_estimators=200, max_depth=3, learning_rate=0.1, random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
        "xgb_combine.fit(X_tr, y_train)\n",
        "\n",
        "y_pred_xgb = xgb_combine.predict(X_te)\n",
        "y_prob_xgb = xgb_combine.predict_proba(X_te)[:, 1]\n",
        "\n",
        "print('XGBoost (combine-only): Drafted vs Undrafted')\n",
        "print('=' * 55)\n",
        "print('Test accuracy:', (y_pred_xgb == y_test).mean().round(4))\n",
        "print('\\nConfusion matrix (rows=actual, cols=predicted):')\n",
        "print(confusion_matrix(y_test, y_pred_xgb))\n",
        "print('\\nClassification report:')\n",
        "print(classification_report(y_test, y_pred_xgb, target_names=['Undrafted', 'Drafted']))\n",
        "print('Test ROC-AUC:', roc_auc_score(y_test, y_prob_xgb).round(4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "893a742f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost (combine + college, train 2017+): Drafted vs Undrafted\n",
            "============================================================\n",
            "Training samples: 46 | Test samples: 54\n",
            "Test accuracy: 0.6852\n",
            "\n",
            "Confusion matrix (rows=actual, cols=predicted):\n",
            "[[10 11]\n",
            " [ 6 27]]\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Undrafted       0.62      0.48      0.54        21\n",
            "     Drafted       0.71      0.82      0.76        33\n",
            "\n",
            "    accuracy                           0.69        54\n",
            "   macro avg       0.67      0.65      0.65        54\n",
            "weighted avg       0.68      0.69      0.67        54\n",
            "\n",
            "Test ROC-AUC: 0.8009\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [16:54:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        }
      ],
      "source": [
        "# XGBoost: combine + college stats (2017+)\n",
        "xgb_college = xgb.XGBClassifier(n_estimators=200, max_depth=2, learning_rate=0.1, random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
        "xgb_college.fit(X_tr17, y_train17)\n",
        "\n",
        "y_pred_xgb17 = xgb_college.predict(X_te17)\n",
        "y_prob_xgb17 = xgb_college.predict_proba(X_te17)[:, 1]\n",
        "\n",
        "print('XGBoost (combine + college, train 2017+): Drafted vs Undrafted')\n",
        "print('=' * 60)\n",
        "print('Training samples:', len(train_2017), '| Test samples:', len(test_2017))\n",
        "print('Test accuracy:', (y_pred_xgb17 == y_test17).mean().round(4))\n",
        "print('\\nConfusion matrix (rows=actual, cols=predicted):')\n",
        "print(confusion_matrix(y_test17, y_pred_xgb17))\n",
        "print('\\nClassification report:')\n",
        "print(classification_report(y_test17, y_pred_xgb17, target_names=['Undrafted', 'Drafted']))\n",
        "print('Test ROC-AUC:', roc_auc_score(y_test17, y_prob_xgb17).round(4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "703b4a86",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combined XGBoost: average of combine-only + college-stats probabilities\n",
            "=================================================================\n",
            "Test accuracy: 0.7778\n",
            "\n",
            "Confusion matrix (rows=actual, cols=predicted):\n",
            "[[11 10]\n",
            " [ 2 31]]\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Undrafted       0.85      0.52      0.65        21\n",
            "     Drafted       0.76      0.94      0.84        33\n",
            "\n",
            "    accuracy                           0.78        54\n",
            "   macro avg       0.80      0.73      0.74        54\n",
            "weighted avg       0.79      0.78      0.76        54\n",
            "\n",
            "Test ROC-AUC: 0.8023\n"
          ]
        }
      ],
      "source": [
        "# Combined XGBoost prediction: average both XGBoost models' probabilities\n",
        "combined_prob_xgb = (y_prob_xgb + y_prob_xgb17) / 2\n",
        "combined_pred_xgb = (combined_prob_xgb >= 0.5).astype(int)\n",
        "\n",
        "print('Combined XGBoost: average of combine-only + college-stats probabilities')\n",
        "print('=' * 65)\n",
        "print('Test accuracy:', (combined_pred_xgb == y_test).mean().round(4))\n",
        "print('\\nConfusion matrix (rows=actual, cols=predicted):')\n",
        "print(confusion_matrix(y_test, combined_pred_xgb))\n",
        "print('\\nClassification report:')\n",
        "print(classification_report(y_test, combined_pred_xgb, target_names=['Undrafted', 'Drafted']))\n",
        "print('Test ROC-AUC:', roc_auc_score(y_test, combined_prob_xgb).round(4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a5f701a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All models ranked by ROC-AUC (same test set, n=93):\n",
            "===========================================================================\n",
            "                     Model  Accuracy  ROC-AUC  Macro F1  Recall (Undrafted)  Recall (Drafted)\n",
            "         Logistic combined  0.851852 0.864358  0.828299            1.000000          1.000000\n",
            "Logistic (combine+college)  0.740741 0.838384  0.722059            0.684211          0.818182\n",
            "   Logistic (combine-only)  0.740741 0.835498  0.676923            0.888889          0.969697\n",
            "         RF (combine-only)  0.740741 0.821068  0.689145            0.818182          0.939394\n",
            "               RF combined  0.703704 0.821068  0.614286            0.857143          0.969697\n",
            "          XGBoost combined  0.777778 0.802309  0.742448            0.846154          0.939394\n",
            " XGBoost (combine+college)  0.685185 0.800866  0.650552            0.625000          0.818182\n",
            "    XGBoost (combine-only)  0.777778 0.793651  0.733553            0.909091          0.969697\n",
            "      RF (combine+college)  0.703704 0.746032  0.656598            0.692308          0.878788\n",
            "\n",
            "Summary:\n",
            "  Best by ROC-AUC: Logistic combined (0.8644)\n",
            "  Best by Macro F1 (balanced Undrafted/Drafted): Logistic combined (0.8283)\n",
            "\n",
            "Conclusion: ROC-AUC is the preferred metric for imbalanced drafted/undrafted;\n",
            "Macro F1 rewards balance. If all models are close, the best single model or\n",
            "combined ensemble is listed above.\n"
          ]
        }
      ],
      "source": [
        "# Compare all drafted/undrafted models on the same test set (y_test, n=93)\n",
        "\n",
        "models = [\n",
        "    ('Logistic (combine-only)', y_pred, y_prob),\n",
        "    ('Logistic (combine+college)', y_pred17, y_prob17),\n",
        "    ('Logistic combined', combined_pred, combined_prob),\n",
        "    ('RF (combine-only)', y_pred_rf, y_prob_rf),\n",
        "    ('RF (combine+college)', y_pred_rf17, y_prob_rf17),\n",
        "    ('RF combined', combined_pred_rf, combined_prob_rf),\n",
        "    ('XGBoost (combine-only)', y_pred_xgb, y_prob_xgb),\n",
        "    ('XGBoost (combine+college)', y_pred_xgb17, y_prob_xgb17),\n",
        "    ('XGBoost combined', combined_pred_xgb, combined_prob_xgb),\n",
        "]\n",
        "\n",
        "results = []\n",
        "for name, pred, prob in models:\n",
        "    acc = (pred == y_test).mean()\n",
        "    auc = roc_auc_score(y_test, prob)\n",
        "    f1_macro = f1_score(y_test, pred, average='macro')\n",
        "    # Per-class recall: Undrafted (0), Drafted (1). CM rows=actual, cols=pred.\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
        "    recall_undrafted = tn / (tn + fn) if (tn + fn) > 0 else 0  # actual undrafted we got right\n",
        "    recall_drafted = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    results.append({\n",
        "        'Model': name,\n",
        "        'Accuracy': acc,\n",
        "        'ROC-AUC': auc,\n",
        "        'Macro F1': f1_macro,\n",
        "        'Recall (Undrafted)': recall_undrafted,\n",
        "        'Recall (Drafted)': recall_drafted,\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df = results_df.sort_values('ROC-AUC', ascending=False).reset_index(drop=True)\n",
        "print('All models ranked by ROC-AUC (same test set, n=93):')\n",
        "print('=' * 75)\n",
        "print(results_df.to_string(index=False))\n",
        "print()\n",
        "\n",
        "best_auc = results_df.loc[0, 'Model']\n",
        "best_auc_val = results_df.loc[0, 'ROC-AUC']\n",
        "best_f1 = results_df.loc[results_df['Macro F1'].idxmax(), 'Model']\n",
        "best_f1_val = results_df['Macro F1'].max()\n",
        "print('Summary:')\n",
        "print('  Best by ROC-AUC:', best_auc, f'({best_auc_val:.4f})')\n",
        "print('  Best by Macro F1 (balanced Undrafted/Drafted):', best_f1, f'({best_f1_val:.4f})')\n",
        "print()\n",
        "print('Conclusion: ROC-AUC is the preferred metric for imbalanced drafted/undrafted;')\n",
        "print('Macro F1 rewards balance. If all models are close, the best single model or')\n",
        "print('combined ensemble is listed above.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2500503",
      "metadata": {},
      "source": [
        "## Projected Round/Day Drafted\n",
        "\n",
        "We are creating 3 models here to see if a player will be drafted or go undrafted based on their combine and college stats. The training set will be data from 2016 - 2020 and our test set will be 2021-2023. The three models we will be testing will be ordinal logistic regression, random tree and XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46adb858",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Draft Day modeling (drafted players only)\n",
            "Train drafted: 170 | Test drafted: 33\n",
            "Train 2017+ drafted: 36 | Test 2017+ drafted: 33\n",
            "Day 1 (R1): 29 train, 6 test\n",
            "Day 2 (R2-3): 65 train, 8 test\n",
            "Day 3 (R4-7): 76 train, 19 test\n"
          ]
        }
      ],
      "source": [
        "# Draft Day modeling: Day 1 (R1), Day 2 (R2-3), Day 3 (R4-7). Train only on DRAFTED players.\n",
        "def round_to_draft_day(r):\n",
        "    if pd.isna(r): return np.nan\n",
        "    r = int(r)\n",
        "    if r == 1: return 1   # Day 1\n",
        "    if r in (2, 3): return 2   # Day 2\n",
        "    if r in (4, 5, 6, 7): return 3   # Day 3\n",
        "    return np.nan\n",
        "\n",
        "# Drafted-only data\n",
        "train_draft = train_df[train_df['Drafted'] == True].copy()\n",
        "test_draft = test_df[test_df['Drafted'] == True].copy()\n",
        "train_draft['draft_day'] = train_draft['Round'].apply(round_to_draft_day)\n",
        "test_draft['draft_day'] = test_draft['Round'].apply(round_to_draft_day)\n",
        "train_draft = train_draft.dropna(subset=['draft_day'])\n",
        "test_draft = test_draft.dropna(subset=['draft_day'])\n",
        "\n",
        "# Ordinal target: 0=Day1, 1=Day2, 2=Day3 (for mord/sklearn)\n",
        "train_draft['draft_day_ord'] = (train_draft['draft_day'] - 1).astype(int)\n",
        "test_draft['draft_day_ord'] = (test_draft['draft_day'] - 1).astype(int)\n",
        "\n",
        "# Combine-only X, y (drafted only)\n",
        "X_draft_tr = train_draft[COMBINE_ONLY_ALL].copy()\n",
        "X_draft_te = test_draft[COMBINE_ONLY_ALL].copy()\n",
        "X_draft_tr = X_draft_tr.fillna(train_medians)\n",
        "X_draft_te = X_draft_te.fillna(train_medians)\n",
        "y_draft_tr = train_draft['draft_day_ord'].values\n",
        "y_draft_te = test_draft['draft_day_ord'].values\n",
        "\n",
        "# Combine+college 2017+ (drafted only)\n",
        "train_draft_17 = train_draft[train_draft['Year'] >= 2017]\n",
        "test_draft_17 = test_draft[test_draft['Year'] >= 2017]\n",
        "X_draft_tr17 = train_draft_17[FEATURES_WITH_COLLEGE_ALL].copy()\n",
        "X_draft_te17 = test_draft_17[FEATURES_WITH_COLLEGE_ALL].copy()\n",
        "X_draft_tr17 = X_draft_tr17.fillna(train_medians17)\n",
        "X_draft_te17 = X_draft_te17.fillna(train_medians17)\n",
        "y_draft_tr17 = train_draft_17['draft_day_ord'].values\n",
        "y_draft_te17 = test_draft_17['draft_day_ord'].values\n",
        "\n",
        "# Scale for ordinal logistic (same scalers as before, but transform draft subsets)\n",
        "X_draft_tr_scaled = scaler.transform(X_draft_tr)\n",
        "X_draft_te_scaled = scaler.transform(X_draft_te)\n",
        "X_draft_tr17_scaled = scaler17.transform(X_draft_tr17)\n",
        "X_draft_te17_scaled = scaler17.transform(X_draft_te17)\n",
        "\n",
        "print('Draft Day modeling (drafted players only)')\n",
        "print('Train drafted:', len(train_draft), '| Test drafted:', len(test_draft))\n",
        "print('Train 2017+ drafted:', len(train_draft_17), '| Test 2017+ drafted:', len(test_draft_17))\n",
        "print('Day 1 (R1):', (train_draft['draft_day']==1).sum(), 'train,', (test_draft['draft_day']==1).sum(), 'test')\n",
        "print('Day 2 (R2-3):', (train_draft['draft_day']==2).sum(), 'train,', (test_draft['draft_day']==2).sum(), 'test')\n",
        "print('Day 3 (R4-7):', (train_draft['draft_day']==3).sum(), 'train,', (test_draft['draft_day']==3).sum(), 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92b413a3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ordinal logit (combine-only)\n",
            "  Accuracy: 0.5455\n",
            "  Confusion matrix (rows=actual, cols=Day1,Day2,Day3):\n",
            " [[ 2  0  4]\n",
            " [ 2  3  3]\n",
            " [ 0  6 13]]\n",
            "  Macro F1: 0.4732\n",
            "\n",
            "Ordinal logit (combine+college)\n",
            "  Accuracy: 0.5455\n",
            "  Confusion matrix (rows=actual, cols=Day1,Day2,Day3):\n",
            " [[ 3  1  2]\n",
            " [ 1  7  0]\n",
            " [ 0 11  8]]\n",
            "  Macro F1: 0.5567\n",
            "\n",
            "Ordinal logit combined\n",
            "  Accuracy: 0.5758\n",
            "  Confusion matrix (rows=actual, cols=Day1,Day2,Day3):\n",
            " [[ 3  1  2]\n",
            " [ 1  7  0]\n",
            " [ 0 10  9]]\n",
            "  Macro F1: 0.5795\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Ordinal logistic (same as drafted/undrafted: two models, combined = average probabilities)\n",
        "# 3 classes: 0=Day1, 1=Day2, 2=Day3 — use multinomial logistic so we have predict_proba\n",
        "ord_combine = LogisticRegression(max_iter=1000, random_state=42)\n",
        "ord_college = LogisticRegression(max_iter=1000, random_state=43)\n",
        "\n",
        "ord_combine.fit(X_draft_tr_scaled, y_draft_tr)\n",
        "prob_ord_combine = ord_combine.predict_proba(X_draft_te_scaled)\n",
        "pred_ord_combine = ord_combine.predict(X_draft_te_scaled).astype(int).clip(0, 2)\n",
        "\n",
        "ord_college.fit(X_draft_tr17_scaled, y_draft_tr17)\n",
        "prob_ord_college = ord_college.predict_proba(X_draft_te17_scaled)\n",
        "pred_ord_college = ord_college.predict(X_draft_te17_scaled).astype(int).clip(0, 2)\n",
        "\n",
        "# Combined: average probabilities (same as drafted/undrafted), then argmax\n",
        "prob_ord_combined = (prob_ord_combine + prob_ord_college) / 2\n",
        "pred_ord_combined = np.argmax(prob_ord_combined, axis=1)\n",
        "\n",
        "day_names = ['Day 1 (R1)', 'Day 2 (R2-3)', 'Day 3 (R4-7)']\n",
        "for name, pred in [('Ordinal logit (combine-only)', pred_ord_combine), ('Ordinal logit (combine+college)', pred_ord_college), ('Ordinal logit combined', pred_ord_combined)]:\n",
        "    y_use = y_draft_te\n",
        "    print(name)\n",
        "    print('  Accuracy:', round((pred == y_use).mean(), 4))\n",
        "    print('  Confusion matrix (rows=actual, cols=Day1,Day2,Day3):\\n', confusion_matrix(y_use, pred))\n",
        "    print('  Macro F1:', round(f1_score(y_use, pred, average='macro', zero_division=0), 4))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a4d0cbb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RF (combine-only)\n",
            "  Accuracy: 0.6061\n",
            "  Confusion matrix:\n",
            " [[ 1  0  5]\n",
            " [ 0  3  5]\n",
            " [ 0  3 16]]\n",
            "  Macro F1: 0.4751\n",
            "\n",
            "RF (combine+college)\n",
            "  Accuracy: 0.5758\n",
            "  Confusion matrix:\n",
            " [[ 0  0  6]\n",
            " [ 0  4  4]\n",
            " [ 0  4 15]]\n",
            "  Macro F1: 0.3939\n",
            "\n",
            "RF combined\n",
            "  Accuracy: 0.5455\n",
            "  Confusion matrix:\n",
            " [[ 0  0  6]\n",
            " [ 0  3  5]\n",
            " [ 0  4 15]]\n",
            "  Macro F1: 0.3556\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Random Forest: draft day — combine-only, combine+college, combined\n",
        "rf_day_combine = RandomForestClassifier(n_estimators=200, max_depth=3, random_state=42)\n",
        "rf_day_combine.fit(X_draft_tr, y_draft_tr)\n",
        "pred_rf_day_combine = rf_day_combine.predict(X_draft_te)\n",
        "prob_rf_day_combine = rf_day_combine.predict_proba(X_draft_te)\n",
        "\n",
        "rf_day_college = RandomForestClassifier(n_estimators=200, max_depth=2, random_state=42)\n",
        "rf_day_college.fit(X_draft_tr17, y_draft_tr17)\n",
        "pred_rf_day_college = rf_day_college.predict(X_draft_te17)\n",
        "prob_rf_day_college = rf_day_college.predict_proba(X_draft_te17)\n",
        "\n",
        "# Combined: average class probabilities, then argmax\n",
        "prob_rf_day_combined = (prob_rf_day_combine + prob_rf_day_college) / 2\n",
        "pred_rf_day_combined = np.argmax(prob_rf_day_combined, axis=1)\n",
        "\n",
        "for name, pred in [('RF (combine-only)', pred_rf_day_combine), ('RF (combine+college)', pred_rf_day_college), ('RF combined', pred_rf_day_combined)]:\n",
        "    y_use = y_draft_te\n",
        "    print(name)\n",
        "    print('  Accuracy:', round((pred == y_use).mean(), 4))\n",
        "    print('  Confusion matrix:\\n', confusion_matrix(y_use, pred))\n",
        "    print('  Macro F1:', round(f1_score(y_use, pred, average='macro', zero_division=0), 4))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a265f5c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [16:57:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/opt/anaconda3/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [16:57:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost (combine-only)\n",
            "  Accuracy: 0.5152\n",
            "  Confusion matrix:\n",
            " [[ 1  2  3]\n",
            " [ 2  4  2]\n",
            " [ 1  6 12]]\n",
            "  Macro F1: 0.4222\n",
            "\n",
            "XGBoost (combine+college)\n",
            "  Accuracy: 0.6667\n",
            "  Confusion matrix:\n",
            " [[ 4  0  2]\n",
            " [ 2  5  1]\n",
            " [ 2  4 13]]\n",
            "  Macro F1: 0.6342\n",
            "\n",
            "XGBoost combined\n",
            "  Accuracy: 0.5758\n",
            "  Confusion matrix:\n",
            " [[ 2  1  3]\n",
            " [ 2  4  2]\n",
            " [ 2  4 13]]\n",
            "  Macro F1: 0.5022\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# XGBoost: draft day — combine-only, combine+college, combined\n",
        "xgb_day_combine = xgb.XGBClassifier(n_estimators=200, max_depth=2, learning_rate=0.1, random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n",
        "xgb_day_combine.fit(X_draft_tr, y_draft_tr)\n",
        "pred_xgb_day_combine = xgb_day_combine.predict(X_draft_te)\n",
        "prob_xgb_day_combine = xgb_day_combine.predict_proba(X_draft_te)\n",
        "\n",
        "xgb_day_college = xgb.XGBClassifier(n_estimators=200, max_depth=7, learning_rate=0.1, random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n",
        "xgb_day_college.fit(X_draft_tr17, y_draft_tr17)\n",
        "pred_xgb_day_college = xgb_day_college.predict(X_draft_te17)\n",
        "prob_xgb_day_college = xgb_day_college.predict_proba(X_draft_te17)\n",
        "\n",
        "# Combined: average class probabilities, then argmax\n",
        "prob_xgb_day_combined = (prob_xgb_day_combine + prob_xgb_day_college) / 2\n",
        "pred_xgb_day_combined = np.argmax(prob_xgb_day_combined, axis=1)\n",
        "\n",
        "for name, pred in [('XGBoost (combine-only)', pred_xgb_day_combine), ('XGBoost (combine+college)', pred_xgb_day_college), ('XGBoost combined', pred_xgb_day_combined)]:\n",
        "    y_use = y_draft_te\n",
        "    print(name)\n",
        "    print('  Accuracy:', round((pred == y_use).mean(), 4))\n",
        "    print('  Confusion matrix:\\n', confusion_matrix(y_use, pred))\n",
        "    print('  Macro F1:', round(f1_score(y_use, pred, average='macro', zero_division=0), 4))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7fcb0be",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Draft-day models ranked by Macro F1 (test set: drafted only, n=33)\n",
            "================================================================================\n",
            "                          Model  Accuracy  Macro F1  Recall Day1  Recall Day2  Recall Day3\n",
            "      XGBoost (combine+college)  0.666667  0.634174     0.666667        0.625     0.684211\n",
            "         Ordinal logit combined  0.575758  0.579487     0.500000        0.875     0.473684\n",
            "Ordinal logit (combine+college)  0.545455  0.556748     0.500000        0.875     0.421053\n",
            "               XGBoost combined  0.575758  0.502208     0.333333        0.500     0.684211\n",
            "              RF (combine-only)  0.606061  0.475132     0.166667        0.375     0.842105\n",
            "   Ordinal logit (combine-only)  0.545455  0.473203     0.333333        0.375     0.684211\n",
            "         XGBoost (combine-only)  0.515152  0.422222     0.166667        0.500     0.631579\n",
            "           RF (combine+college)  0.575758  0.393939     0.000000        0.500     0.789474\n",
            "                    RF combined  0.545455  0.355556     0.000000        0.375     0.789474\n",
            "\n",
            "Summary:\n",
            "  Best by Accuracy: XGBoost (combine+college) (0.6667)\n",
            "  Best by Macro F1: XGBoost (combine+college) (0.6342)\n"
          ]
        }
      ],
      "source": [
        "# Compare all draft-day models (same test set: drafted players only, y_draft_te)\n",
        "day_models = [\n",
        "    ('Ordinal logit (combine-only)', pred_ord_combine),\n",
        "    ('Ordinal logit (combine+college)', pred_ord_college),\n",
        "    ('Ordinal logit combined', pred_ord_combined),\n",
        "    ('RF (combine-only)', pred_rf_day_combine),\n",
        "    ('RF (combine+college)', pred_rf_day_college),\n",
        "    ('RF combined', pred_rf_day_combined),\n",
        "    ('XGBoost (combine-only)', pred_xgb_day_combine),\n",
        "    ('XGBoost (combine+college)', pred_xgb_day_college),\n",
        "    ('XGBoost combined', pred_xgb_day_combined),\n",
        "]\n",
        "\n",
        "day_results = []\n",
        "for name, pred in day_models:\n",
        "    acc = (pred == y_draft_te).mean()\n",
        "    f1 = f1_score(y_draft_te, pred, average='macro', zero_division=0)\n",
        "    cm = confusion_matrix(y_draft_te, pred)\n",
        "    # Per-class recall: Day1=0, Day2=1, Day3=2\n",
        "    recalls = []\n",
        "    for k in range(3):\n",
        "        if cm.shape[0] > k and cm[k].sum() > 0:\n",
        "            recalls.append(cm[k, k] / cm[k].sum())\n",
        "        else:\n",
        "            recalls.append(np.nan)\n",
        "    day_results.append({\n",
        "        'Model': name,\n",
        "        'Accuracy': acc,\n",
        "        'Macro F1': f1,\n",
        "        'Recall Day1': recalls[0] if not np.isnan(recalls[0]) else None,\n",
        "        'Recall Day2': recalls[1] if not np.isnan(recalls[1]) else None,\n",
        "        'Recall Day3': recalls[2] if not np.isnan(recalls[2]) else None,\n",
        "    })\n",
        "\n",
        "day_df = pd.DataFrame(day_results)\n",
        "day_df = day_df.sort_values('Macro F1', ascending=False).reset_index(drop=True)\n",
        "print('Draft-day models ranked by Macro F1 (test set: drafted only, n=' + str(len(y_draft_te)) + ')')\n",
        "print('=' * 80)\n",
        "print(day_df.to_string(index=False))\n",
        "print()\n",
        "best_acc = day_df.loc[day_df['Accuracy'].idxmax(), 'Model']\n",
        "best_acc_val = day_df['Accuracy'].max()\n",
        "best_f1 = day_df.loc[0, 'Model']\n",
        "best_f1_val = day_df.loc[0, 'Macro F1']\n",
        "print('Summary:')\n",
        "print('  Best by Accuracy:', best_acc, '(' + str(round(best_acc_val, 4)) + ')')\n",
        "print('  Best by Macro F1:', best_f1, '(' + str(round(best_f1_val, 4)) + ')')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ece3bc6",
      "metadata": {},
      "source": [
        "## Pipeline: Drafted/Undrafted + Draft Day\n",
        "\n",
        "Test every combination of (drafted/undrafted model) × (draft-day model). Pipeline: if predicted undrafted → \"Undrafted\"; if predicted drafted → use draft-day model to get Day 1, 2, or 3. Evaluate on 4-class: Undrafted, Day 1, Day 2, Day 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d557da76",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All 81 combinations (Drafted/Undrafted × Draft Day), ranked by Macro F1\n",
            "==========================================================================================\n",
            " Drafted/Undrafted         Draft Day  Accuracy  Macro F1\n",
            " Logistic combined     XGB (college)  0.648148  0.621935\n",
            " Logistic combined  Ordinal combined  0.592593  0.581112\n",
            "      XGB combined     XGB (college)  0.574074  0.573109\n",
            " Logistic combined Ordinal (college)  0.574074  0.565877\n",
            "     XGB (combine)     XGB (college)  0.574074  0.554958\n",
            "Logistic (college)  Ordinal combined  0.555556  0.545076\n",
            "      RF (combine)     XGB (college)  0.537037  0.540754\n",
            "Logistic (college)     XGB (college)  0.555556  0.538480\n",
            "     XGB (college)     XGB (college)  0.518519  0.537551\n",
            "      XGB combined  Ordinal combined  0.537037  0.537414\n",
            " Logistic combined      XGB combined  0.592593  0.530373\n",
            "Logistic (college) Ordinal (college)  0.537037  0.528239\n",
            "      RF (college)     XGB (college)  0.518519  0.526526\n",
            "Logistic (combine)     XGB (college)  0.537037  0.525618\n",
            "     XGB (combine)  Ordinal combined  0.518519  0.521741\n",
            "      XGB combined Ordinal (college)  0.518519  0.520856\n",
            " Logistic combined      RF (combine)  0.611111  0.510539\n",
            "     XGB (combine) Ordinal (college)  0.500000  0.508523\n",
            "      RF (combine)  Ordinal combined  0.500000  0.507941\n",
            " Logistic combined Ordinal (combine)  0.574074  0.505570\n",
            "       RF combined     XGB (college)  0.500000  0.502490\n",
            "      XGB combined      XGB combined  0.537037  0.492698\n",
            "      RF (combine) Ordinal (college)  0.481481  0.492424\n",
            "      RF (college)  Ordinal combined  0.481481  0.492209\n",
            "Logistic (combine)  Ordinal combined  0.481481  0.491319\n",
            "      XGB combined Ordinal (combine)  0.537037  0.480152\n",
            "Logistic (combine) Ordinal (college)  0.462963  0.477733\n",
            "      RF (college) Ordinal (college)  0.462963  0.477050\n",
            "      XGB combined      RF (combine)  0.555556  0.475638\n",
            "     XGB (college)  Ordinal combined  0.462963  0.475119\n",
            "       RF combined  Ordinal combined  0.462963  0.474831\n",
            " Logistic combined     XGB (combine)  0.555556  0.473811\n",
            "Logistic (college)      RF (combine)  0.555556  0.473447\n",
            "     XGB (combine) Ordinal (combine)  0.518519  0.462311\n",
            "Logistic (college) Ordinal (combine)  0.518519  0.462274\n",
            "Logistic (college)      XGB combined  0.518519  0.461378\n",
            "       RF combined Ordinal (college)  0.444444  0.460678\n",
            "     XGB (combine)      XGB combined  0.518519  0.459848\n",
            "Logistic (combine)      XGB combined  0.500000  0.456824\n",
            "     XGB (college) Ordinal (college)  0.444444  0.456767\n",
            "Logistic (college)     XGB (combine)  0.537037  0.455970\n",
            " Logistic combined      RF (college)  0.592593  0.455882\n",
            "     XGB (college)      XGB combined  0.481481  0.455163\n",
            "      RF (college)      XGB combined  0.481481  0.451923\n",
            "      RF (combine)      XGB combined  0.481481  0.447811\n",
            "      RF (combine)      RF (combine)  0.518519  0.441106\n",
            "      RF (college)      RF (combine)  0.500000  0.436611\n",
            "Logistic (combine)      RF (combine)  0.518519  0.435012\n",
            "     XGB (combine)      RF (combine)  0.537037  0.434436\n",
            "      XGB combined     XGB (combine)  0.500000  0.431676\n",
            " Logistic combined       RF combined  0.574074  0.429157\n",
            "      RF (combine) Ordinal (combine)  0.462963  0.423958\n",
            "     XGB (college)      RF (combine)  0.481481  0.422635\n",
            "     XGB (combine)      RF (college)  0.537037  0.415406\n",
            "     XGB (combine)     XGB (combine)  0.481481  0.413243\n",
            "       RF combined      XGB combined  0.444444  0.411726\n",
            "Logistic (combine) Ordinal (combine)  0.462963  0.407596\n",
            "      XGB combined      RF (college)  0.518519  0.406863\n",
            "      RF (combine)     XGB (combine)  0.462963  0.403580\n",
            "Logistic (college)      RF (college)  0.518519  0.402369\n",
            "Logistic (combine)     XGB (combine)  0.462963  0.402052\n",
            "     XGB (college) Ordinal (combine)  0.444444  0.397248\n",
            "      RF (college) Ordinal (combine)  0.444444  0.396732\n",
            "       RF combined      RF (combine)  0.462963  0.391865\n",
            "       RF combined Ordinal (combine)  0.425926  0.389564\n",
            "     XGB (combine)       RF combined  0.518519  0.388889\n",
            "Logistic (combine)      RF (college)  0.500000  0.387344\n",
            "     XGB (college)     XGB (combine)  0.444444  0.381522\n",
            "      RF (combine)      RF (college)  0.481481  0.380914\n",
            "      XGB combined       RF combined  0.500000  0.380515\n",
            "      RF (college)     XGB (combine)  0.444444  0.380188\n",
            "Logistic (college)       RF combined  0.500000  0.375815\n",
            "     XGB (college)      RF (college)  0.462963  0.372380\n",
            "       RF combined     XGB (combine)  0.425926  0.369055\n",
            "      RF (college)      RF (college)  0.462963  0.367647\n",
            "Logistic (combine)       RF combined  0.481481  0.361012\n",
            "      RF (combine)       RF combined  0.462963  0.354745\n",
            "       RF combined      RF (college)  0.444444  0.347597\n",
            "     XGB (college)       RF combined  0.444444  0.345135\n",
            "      RF (college)       RF combined  0.444444  0.341488\n",
            "       RF combined       RF combined  0.425926  0.321583\n",
            "\n",
            "Top 10 combinations:\n",
            " Drafted/Undrafted         Draft Day  Accuracy  Macro F1\n",
            " Logistic combined     XGB (college)  0.648148  0.621935\n",
            " Logistic combined  Ordinal combined  0.592593  0.581112\n",
            "      XGB combined     XGB (college)  0.574074  0.573109\n",
            " Logistic combined Ordinal (college)  0.574074  0.565877\n",
            "     XGB (combine)     XGB (college)  0.574074  0.554958\n",
            "Logistic (college)  Ordinal combined  0.555556  0.545076\n",
            "      RF (combine)     XGB (college)  0.537037  0.540754\n",
            "Logistic (college)     XGB (college)  0.555556  0.538480\n",
            "     XGB (college)     XGB (college)  0.518519  0.537551\n",
            "      XGB combined  Ordinal combined  0.537037  0.537414\n",
            "\n",
            "Best pair: Logistic combined + XGB (college) | Macro F1 = 0.6219 | Accuracy = 0.6481\n"
          ]
        }
      ],
      "source": [
        "# Actual 4-class labels for full test set: 0=Undrafted, 1=Day1, 2=Day2, 3=Day3\n",
        "def round_to_draft_day(r):\n",
        "    if pd.isna(r): return np.nan\n",
        "    r = int(r)\n",
        "    if r == 1: return 1\n",
        "    if r in (2, 3): return 2\n",
        "    if r in (4, 5, 6, 7): return 3\n",
        "    return np.nan\n",
        "\n",
        "y_actual_4 = []\n",
        "for _, row in test_df.iterrows():\n",
        "    if not row['Drafted']:\n",
        "        y_actual_4.append(0)\n",
        "    else:\n",
        "        d = round_to_draft_day(row['Round'])\n",
        "        y_actual_4.append(int(d))  # 1, 2, or 3\n",
        "y_actual_4 = np.array(y_actual_4)\n",
        "\n",
        "# Full-test draft-day predictions (length = len(test_df)) for each draft-day model\n",
        "day_ord_c = ord_combine.predict(X_te_scaled).astype(int).clip(0, 2)\n",
        "day_ord_17 = ord_college.predict(X_te17_scaled).astype(int).clip(0, 2)\n",
        "day_ord_comb = np.argmax((ord_combine.predict_proba(X_te_scaled) + ord_college.predict_proba(X_te17_scaled)) / 2, axis=1)\n",
        "day_rf_c = rf_day_combine.predict(X_te)\n",
        "day_rf_17 = rf_day_college.predict(X_te17)\n",
        "day_rf_comb = np.argmax((rf_day_combine.predict_proba(X_te) + rf_day_college.predict_proba(X_te17)) / 2, axis=1)\n",
        "day_xgb_c = xgb_day_combine.predict(X_te)\n",
        "day_xgb_17 = xgb_day_college.predict(X_te17)\n",
        "day_xgb_comb = np.argmax((xgb_day_combine.predict_proba(X_te) + xgb_day_college.predict_proba(X_te17)) / 2, axis=1)\n",
        "\n",
        "drafted_models = [\n",
        "    ('Logistic (combine)', y_pred),\n",
        "    ('Logistic (college)', y_pred17),\n",
        "    ('Logistic combined', combined_pred),\n",
        "    ('RF (combine)', y_pred_rf),\n",
        "    ('RF (college)', y_pred_rf17),\n",
        "    ('RF combined', combined_pred_rf),\n",
        "    ('XGB (combine)', y_pred_xgb),\n",
        "    ('XGB (college)', y_pred_xgb17),\n",
        "    ('XGB combined', combined_pred_xgb),\n",
        "]\n",
        "day_models_full = [\n",
        "    ('Ordinal (combine)', day_ord_c),\n",
        "    ('Ordinal (college)', day_ord_17),\n",
        "    ('Ordinal combined', day_ord_comb),\n",
        "    ('RF (combine)', day_rf_c),\n",
        "    ('RF (college)', day_rf_17),\n",
        "    ('RF combined', day_rf_comb),\n",
        "    ('XGB (combine)', day_xgb_c),\n",
        "    ('XGB (college)', day_xgb_17),\n",
        "    ('XGB combined', day_xgb_comb),\n",
        "]\n",
        "\n",
        "# For each combination: pred_4 = 0 if drafted_pred==0 else (1 + day_pred)\n",
        "results = []\n",
        "for dname, d_pred in drafted_models:\n",
        "    for dayname, day_pred in day_models_full:\n",
        "        pred_4 = np.where(d_pred == 0, 0, 1 + day_pred.astype(int).clip(0, 2))\n",
        "        acc = (pred_4 == y_actual_4).mean()\n",
        "        f1 = f1_score(y_actual_4, pred_4, average='macro', zero_division=0)\n",
        "        results.append({'Drafted/Undrafted': dname, 'Draft Day': dayname, 'Accuracy': acc, 'Macro F1': f1})\n",
        "\n",
        "pipe_df = pd.DataFrame(results)\n",
        "pipe_df = pipe_df.sort_values('Macro F1', ascending=False).reset_index(drop=True)\n",
        "print('All 81 combinations (Drafted/Undrafted × Draft Day), ranked by Macro F1')\n",
        "print('=' * 90)\n",
        "print(pipe_df.to_string(index=False))\n",
        "print()\n",
        "print('Top 10 combinations:')\n",
        "print(pipe_df.head(10).to_string(index=False))\n",
        "print()\n",
        "print('Best pair:', pipe_df.loc[0, 'Drafted/Undrafted'], '+', pipe_df.loc[0, 'Draft Day'],\n",
        "      '| Macro F1 =', round(pipe_df.loc[0, 'Macro F1'], 4), '| Accuracy =', round(pipe_df.loc[0, 'Accuracy'], 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f220f1a",
      "metadata": {},
      "source": [
        "## Predict draft for a single player\n",
        "\n",
        "Function that selects the best pipeline (drafted/undrafted + draft day) based on what stats the player has, then returns the prediction. If the player has no college stats, only combine-only model pairs are considered."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc89cb23",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'drafted': np.True_,\n",
              " 'draft_day': 2,\n",
              " 'drafted_model': 'Logistic combined',\n",
              " 'day_model': 'XGB (college)',\n",
              " 'prob_drafted': 0.9374035489568803}"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def _player_has_college_stats(player_dict):\n",
        "    \"\"\"True if player has all three college stats (non-null).\"\"\"\n",
        "    keys = ['QB_Hurry_final_season', 'TFL_final_season', 'Sacks_final_season']\n",
        "    for k in keys:\n",
        "        v = player_dict.get(k, player_dict.get(k.replace('_', ' ')))\n",
        "        if v is None or (isinstance(v, float) and np.isnan(v)):\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def _get_val(player_dict, *keys, default=np.nan):\n",
        "    for k in keys:\n",
        "        if k in player_dict and player_dict[k] is not None:\n",
        "            v = player_dict[k]\n",
        "            if isinstance(v, float) and np.isnan(v):\n",
        "                continue\n",
        "            return v\n",
        "    return default\n",
        "\n",
        "def _height_inches(h):\n",
        "    if h is None or (isinstance(h, float) and np.isnan(h)):\n",
        "        return np.nan\n",
        "    if isinstance(h, (int, float)):\n",
        "        return float(h)\n",
        "    if isinstance(h, str) and '-' in h:\n",
        "        parts = h.strip().split('-')\n",
        "        return int(parts[0]) * 12 + int(parts[1])\n",
        "    return np.nan\n",
        "\n",
        "# Map contains_* column name -> feature name for checking if player has that stat\n",
        "CONTAINS_TO_FEATURE = {\n",
        "    'contains_broad_jump': 'Broad Jump', 'contains_vertical': 'Vertical', 'contains_shuttle': 'Shuttle',\n",
        "    'contains_three_cone': '3Cone', 'contains_40yd': '40yd', 'contains_height': 'Height', 'contains_weight': 'Weight',\n",
        "    'contains_speed_score': 'speed_score', 'contains_explosive_score': 'explosive_score', 'contains_agility_score': 'agility_score',\n",
        "    'contains_qb_hurry_final_season': 'QB_Hurry_final_season', 'contains_tfl_final_season': 'TFL_final_season', 'contains_sacks_final_season': 'Sacks_final_season',\n",
        "    'contains_sacks_cumulative': 'Sacks_cumulative', 'contains_tfl_cumulative': 'TFL_cumulative', 'contains_qb_hurry_cumulative': 'QB_Hurry_cumulative',\n",
        "    'contains_p4_conference': 'p4_conference',\n",
        "}\n",
        "\n",
        "def _player_row(player_dict, feature_list, contains_list, medians, add_speed=True):\n",
        "    \"\"\"Build one row for the player with feature_list + contains_*; fill missing with medians.\"\"\"\n",
        "    row = {}\n",
        "    for col in feature_list:\n",
        "        v = _get_val(player_dict, col, col.replace(' ', '_').lower(), col.replace(' ', ''))\n",
        "        if col == 'Height':\n",
        "            v = _height_inches(v)\n",
        "        if add_speed and col == 'speed_score' and (v is np.nan or (isinstance(v, float) and np.isnan(v))):\n",
        "            w, forty = _get_val(player_dict, 'Weight'), _get_val(player_dict, '40yd')\n",
        "            if w is not np.nan and forty is not np.nan and float(forty) > 0:\n",
        "                v = float(w) * 200 / (float(forty) ** 4)\n",
        "        row[col] = v if (v is not np.nan and not (isinstance(v, float) and np.isnan(v))) else medians.get(col, np.nan)\n",
        "    for col in contains_list:\n",
        "        feat = CONTAINS_TO_FEATURE.get(col, col.replace('contains_', '').replace('_', ' '))\n",
        "        v = _get_val(player_dict, feat, feat.replace(' ', '_').lower() if isinstance(feat, str) else feat)\n",
        "        row[col] = 1 if (v is not None and v is not np.nan and not (isinstance(v, float) and np.isnan(v))) else 0\n",
        "    return pd.Series(row)\n",
        "\n",
        "def get_best_pipeline_for_player(player_dict, pipe_df):\n",
        "    \"\"\"Select best (drafted/undrafted, draft day) model pair given what player data is available.\"\"\"\n",
        "    has_college = _player_has_college_stats(player_dict)\n",
        "    if not has_college:\n",
        "        # Restrict to combine-only models (exclude 'college' and 'combined')\n",
        "        drafted_ok = pipe_df['Drafted/Undrafted'].isin(['Logistic (combine)', 'RF (combine)', 'XGB (combine)'])\n",
        "        day_ok = pipe_df['Draft Day'].isin(['Ordinal (combine)', 'RF (combine)', 'XGB (combine)'])\n",
        "        sub = pipe_df[drafted_ok & day_ok].sort_values('Macro F1', ascending=False)\n",
        "        if len(sub) == 0:\n",
        "            sub = pipe_df\n",
        "    else:\n",
        "        sub = pipe_df\n",
        "    best = sub.iloc[0]\n",
        "    return best['Drafted/Undrafted'], best['Draft Day']\n",
        "\n",
        "def _run_drafted_model(drafted_name, row_combine, row_full):\n",
        "    \"\"\"Return P(drafted) in [0,1] for the given model name.\"\"\"\n",
        "    if drafted_name == 'Logistic (combine)':\n",
        "        return logit_draft.predict_proba(scaler.transform(row_combine.to_frame().T))[0, 1]\n",
        "    if drafted_name == 'Logistic (college)':\n",
        "        return logit_draft_college.predict_proba(scaler17.transform(row_full.to_frame().T))[0, 1]\n",
        "    if drafted_name == 'Logistic combined':\n",
        "        p1 = logit_draft.predict_proba(scaler.transform(row_combine.to_frame().T))[0, 1]\n",
        "        p2 = logit_draft_college.predict_proba(scaler17.transform(row_full.to_frame().T))[0, 1]\n",
        "        return (p1 + p2) / 2\n",
        "    if drafted_name == 'RF (combine)':\n",
        "        return rf_combine.predict_proba(row_combine.to_frame().T)[0, 1]\n",
        "    if drafted_name == 'RF (college)':\n",
        "        return rf_college.predict_proba(row_full.to_frame().T)[0, 1]\n",
        "    if drafted_name == 'RF combined':\n",
        "        p1 = rf_combine.predict_proba(row_combine.to_frame().T)[0, 1]\n",
        "        p2 = rf_college.predict_proba(row_full.to_frame().T)[0, 1]\n",
        "        return (p1 + p2) / 2\n",
        "    if drafted_name == 'XGB (combine)':\n",
        "        return xgb_combine.predict_proba(row_combine.to_frame().T)[0, 1]\n",
        "    if drafted_name == 'XGB (college)':\n",
        "        return xgb_college.predict_proba(row_full.to_frame().T)[0, 1]\n",
        "    if drafted_name == 'XGB combined':\n",
        "        p1 = xgb_combine.predict_proba(row_combine.to_frame().T)[0, 1]\n",
        "        p2 = xgb_college.predict_proba(row_full.to_frame().T)[0, 1]\n",
        "        return (p1 + p2) / 2\n",
        "    return 0.0\n",
        "\n",
        "def _run_day_model(day_name, row_combine, row_full):\n",
        "    \"\"\"Return class 0/1/2 (Day1/Day2/Day3) for the given model name.\"\"\"\n",
        "    if day_name == 'Ordinal (combine)':\n",
        "        return int(ord_combine.predict(scaler.transform(row_combine.to_frame().T))[0])\n",
        "    if day_name == 'Ordinal (college)':\n",
        "        return int(ord_college.predict(scaler17.transform(row_full.to_frame().T))[0])\n",
        "    if day_name == 'Ordinal combined':\n",
        "        p1 = ord_combine.predict_proba(scaler.transform(row_combine.to_frame().T))[0]\n",
        "        p2 = ord_college.predict_proba(scaler17.transform(row_full.to_frame().T))[0]\n",
        "        return int(np.argmax((p1 + p2) / 2))\n",
        "    if day_name == 'RF (combine)':\n",
        "        return int(rf_day_combine.predict(row_combine.to_frame().T)[0])\n",
        "    if day_name == 'RF (college)':\n",
        "        return int(rf_day_college.predict(row_full.to_frame().T)[0])\n",
        "    if day_name == 'RF combined':\n",
        "        p1 = rf_day_combine.predict_proba(row_combine.to_frame().T)[0]\n",
        "        p2 = rf_day_college.predict_proba(row_full.to_frame().T)[0]\n",
        "        return int(np.argmax((p1 + p2) / 2))\n",
        "    if day_name == 'XGB (combine)':\n",
        "        return int(xgb_day_combine.predict(row_combine.to_frame().T)[0])\n",
        "    if day_name == 'XGB (college)':\n",
        "        return int(xgb_day_college.predict(row_full.to_frame().T)[0])\n",
        "    if day_name == 'XGB combined':\n",
        "        p1 = xgb_day_combine.predict_proba(row_combine.to_frame().T)[0]\n",
        "        p2 = xgb_day_college.predict_proba(row_full.to_frame().T)[0]\n",
        "        return int(np.argmax((p1 + p2) / 2))\n",
        "    return 2\n",
        "\n",
        "def predict_draft(player_dict, pipe_df=None):\n",
        "    \"\"\"\n",
        "    Predict drafted/undrafted and (if drafted) draft day for one player.\n",
        "    player_dict: keys like Height, Weight, 40yd, Vertical, Broad Jump, Shuttle, 3Cone,\n",
        "                 QB_Hurry_final_season, TFL_final_season, Sacks_final_season.\n",
        "                 Height can be inches (int) or \"6-4\". Missing stats can be omitted or None.\n",
        "    If college stats are missing, the best combine-only pipeline is used.\n",
        "    Returns: dict with drafted (bool), draft_day (1|2|3 or None), drafted_model, day_model.\n",
        "    \"\"\"\n",
        "    if pipe_df is None:\n",
        "        pipe_df = globals().get('pipe_df')\n",
        "    if pipe_df is None:\n",
        "        raise ValueError('Run the pipeline comparison cell first to create pipe_df, or pass pipe_df.')\n",
        "    drafted_name, day_name = get_best_pipeline_for_player(player_dict, pipe_df)\n",
        "    row_combine = _player_row(player_dict, COMBINE_ONLY_FEATURES, COMBINE_ONLY_CONTAINS, train_medians)\n",
        "    row_combine = row_combine.reindex(COMBINE_ONLY_ALL).fillna(train_medians)\n",
        "    row_full = _player_row(player_dict, FEATURES_WITH_COLLEGE, CONTAINS_WITH_COLLEGE, train_medians17)\n",
        "    row_full = row_full.reindex(FEATURES_WITH_COLLEGE_ALL).fillna(train_medians17)\n",
        "    prob_drafted = _run_drafted_model(drafted_name, row_combine, row_full)\n",
        "    drafted = prob_drafted >= 0.5\n",
        "    draft_day = None\n",
        "    if drafted:\n",
        "        day_class = _run_day_model(day_name, row_combine, row_full)\n",
        "        draft_day = int(np.clip(day_class, 0, 2)) + 1  # 0->Day1, 1->Day2, 2->Day3\n",
        "    return {\n",
        "        'drafted': drafted,\n",
        "        'draft_day': draft_day,\n",
        "        'drafted_model': drafted_name,\n",
        "        'day_model': day_name,\n",
        "        'prob_drafted': float(prob_drafted),\n",
        "    }\n",
        "\n",
        "# Example (run after all model cells):\n",
        "player = {'Height': '6-4', 'Weight': 265, '40yd': 4.65, 'Vertical': 35, 'Broad Jump': 118,\n",
        "          'Shuttle': 4.4, '3Cone': 7.2, 'QB_Hurry_final_season': 12, 'TFL_final_season': 10, 'Sacks_final_season': 6}\n",
        "predict_draft(player)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a49300db",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Draft predictions (best pipeline) + variance across all pipelines\n",
            "======================================================================\n",
            "Peter Woods: Day 1  (P(drafted)=0.990)\n",
            "  Best models: Logistic combined + XGB (college)\n",
            "  P(drafted) across 81 pipelines: mean = 0.921, std = 0.107, variance = 0.0113\n",
            "  Draft day (when predicted drafted): mean = 2.33, std = 0.67, variance = 0.4444\n",
            "  Draft day distribution: Day1=9, Day2=36, Day3=36\n",
            "\n",
            "Caleb Banks: Day 3  (P(drafted)=0.946)\n",
            "  Best models: Logistic combined + XGB (college)\n",
            "  P(drafted) across 81 pipelines: mean = 0.914, std = 0.072, variance = 0.0052\n",
            "  Draft day (when predicted drafted): mean = 2.67, std = 0.47, variance = 0.2222\n",
            "  Draft day distribution: Day1=0, Day2=27, Day3=54\n",
            "\n",
            "Kayden McDonald: Day 3  (P(drafted)=0.937)\n",
            "  Best models: Logistic combined + XGB (college)\n",
            "  P(drafted) across 81 pipelines: mean = 0.838, std = 0.143, variance = 0.0205\n",
            "  Draft day (when predicted drafted): mean = 3.00, std = 0.00, variance = 0.0000\n",
            "  Draft day distribution: Day1=0, Day2=0, Day3=81\n",
            "\n",
            "Christen Miller: Day 2  (P(drafted)=0.950)\n",
            "  Best models: Logistic combined + XGB (college)\n",
            "  P(drafted) across 81 pipelines: mean = 0.902, std = 0.112, variance = 0.0125\n",
            "  Draft day (when predicted drafted): mean = 2.56, std = 0.50, variance = 0.2469\n",
            "  Draft day distribution: Day1=0, Day2=36, Day3=45\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Example predictions: Peter Woods, Caleb Banks, Kayden McDonald, Christen Miller\n",
        "# Stats from listed measurements and college production; combine values are estimates where not reported.\n",
        "# Optional: Sacks_cumulative, TFL_cumulative, QB_Hurry_cumulative — if provided, the college/combined\n",
        "# models use them; if omitted or None, training medians are used.\n",
        "\n",
        "examples = {\n",
        "    'Peter Woods': {\n",
        "        'Height': '6-3', 'Weight': 310,\n",
        "        '40yd': 4.75, 'Vertical': None, 'Broad Jump': None,\n",
        "        'Shuttle': None, '3Cone': None,\n",
        "        'QB_Hurry_final_season': 9, 'TFL_final_season': 3.5, 'Sacks_final_season': 3.5,  # Clemson\n",
        "        'Sacks_cumulative': 5, 'TFL_cumulative': 14.5, 'QB_Hurry_cumulative': 42,  # fill in to test with cumulative\n",
        "    },\n",
        "    'Caleb Banks': {\n",
        "        'Height': '6-6', 'Weight': 330,\n",
        "        '40yd': 5.2, 'Vertical': None, 'Broad Jump': None,\n",
        "        'Shuttle': None, '3Cone': None,\n",
        "        'QB_Hurry_final_season': 6, 'TFL_final_season': 7, 'Sacks_final_season': 4.5,  # 2024 Injured in 2025\n",
        "        'Sacks_cumulative': 5.5, 'TFL_cumulative': 9.5, 'QB_Hurry_cumulative': 42,\n",
        "    },\n",
        "    'Kayden McDonald': {\n",
        "        'Height': '6-3', 'Weight': 325,\n",
        "        '40yd': 5.15, 'Vertical': None, 'Broad Jump': None,\n",
        "        'Shuttle': None, '3Cone': None,\n",
        "        'QB_Hurry_final_season': 8, 'TFL_final_season': 9, 'Sacks_final_season': 3,    # Ohio State 2025\n",
        "        'Sacks_cumulative': 3, 'TFL_cumulative': 11, 'QB_Hurry_cumulative': 25,\n",
        "    },\n",
        "    'Christen Miller': {\n",
        "        'Height': '6-4', 'Weight': 305,\n",
        "        '40yd': 4.90, 'Vertical': None, 'Broad Jump': None,\n",
        "        'Shuttle': None, '3Cone': None,\n",
        "        'QB_Hurry_final_season': 14, 'TFL_final_season': 4, 'Sacks_final_season': 1.5,    # Colorado\n",
        "        'Sacks_cumulative': 4, 'TFL_cumulative': 11.5, 'QB_Hurry_cumulative': None,\n",
        "    },\n",
        "}\n",
        "\n",
        "def _all_pipeline_preds(player_dict, pipe_subset):\n",
        "    \"\"\"Run all pipelines in pipe_subset for this player; return arrays of prob_drafted and draft_day (1/2/3 or nan).\"\"\"\n",
        "    row_combine = _player_row(player_dict, COMBINE_ONLY_FEATURES, COMBINE_ONLY_CONTAINS, train_medians)\n",
        "    row_combine = row_combine.reindex(COMBINE_ONLY_ALL).fillna(train_medians)\n",
        "    row_full = _player_row(player_dict, FEATURES_WITH_COLLEGE, CONTAINS_WITH_COLLEGE, train_medians17)\n",
        "    row_full = row_full.reindex(FEATURES_WITH_COLLEGE_ALL).fillna(train_medians17)\n",
        "    probs, days = [], []\n",
        "    for _, r in pipe_subset.iterrows():\n",
        "        p = _run_drafted_model(r['Drafted/Undrafted'], row_combine, row_full)\n",
        "        probs.append(p)\n",
        "        if p >= 0.5:\n",
        "            day_class = _run_day_model(r['Draft Day'], row_combine, row_full)\n",
        "            days.append(int(np.clip(day_class, 0, 2)) + 1)\n",
        "        else:\n",
        "            days.append(np.nan)\n",
        "    return np.array(probs), np.array(days)\n",
        "\n",
        "print('Draft predictions (best pipeline) + variance across all pipelines\\n' + '=' * 70)\n",
        "for name, player_dict in examples.items():\n",
        "    out = predict_draft(player_dict)\n",
        "    day_str = f\"Day {out['draft_day']}\" if out['drafted'] else 'Undrafted'\n",
        "    print(f\"{name}: {day_str}  (P(drafted)={out['prob_drafted']:.3f})\")\n",
        "    print(f\"  Best models: {out['drafted_model']} + {out['day_model']}\")\n",
        "\n",
        "    probs, days = _all_pipeline_preds(player_dict, pipe_df)\n",
        "    p_mean, p_var, p_std = probs.mean(), probs.var(), probs.std()\n",
        "    print(f\"  P(drafted) across {len(probs)} pipelines: mean = {p_mean:.3f}, std = {p_std:.3f}, variance = {p_var:.4f}\")\n",
        "    days_drafted = days[~np.isnan(days)]\n",
        "    if len(days_drafted) > 0:\n",
        "        d_mean, d_var, d_std = days_drafted.mean(), days_drafted.var(), days_drafted.std()\n",
        "        print(f\"  Draft day (when predicted drafted): mean = {d_mean:.2f}, std = {d_std:.2f}, variance = {d_var:.4f}\")\n",
        "        print(f\"  Draft day distribution: Day1={np.sum(days==1)}, Day2={np.sum(days==2)}, Day3={np.sum(days==3)}\")\n",
        "    else:\n",
        "        print(f\"  Draft day: all pipelines predicted Undrafted\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89137dfe",
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'np' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     18\u001b[0m     dt_2024[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHeight\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(dt_2024[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHeight\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m dt_2024[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspeed_score\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(\n\u001b[1;32m     21\u001b[0m     dt_2024[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m40yd\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnotna() \u001b[38;5;241m&\u001b[39m (dt_2024[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m40yd\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m     22\u001b[0m     dt_2024[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeight\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m/\u001b[39m (dt_2024[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m40yd\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m4\u001b[39m),\n\u001b[1;32m     23\u001b[0m     np\u001b[38;5;241m.\u001b[39mnan\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     26\u001b[0m tr_dt \u001b[38;5;241m=\u001b[39m train_df[train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPos\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDT\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     27\u001b[0m mean_v \u001b[38;5;241m=\u001b[39m tr_dt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVertical\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ],
      "source": [
        "# 2024 drafted DTs: compute speed_score, explosive_score, agility_score; run model and add predicted_draft_day\n",
        "# Requires prior cells (train_df, predict_draft, pipe_df, etc.) to be run.\n",
        "\n",
        "dt_2024 = pd.read_csv('dt_drafted_2024.csv')\n",
        "if dt_2024['Height'].dtype == object or (dt_2024['Height'].notna() & (dt_2024['Height'].astype(str).str.contains('-', na=False))).any():\n",
        "    def _ht_inches(h):\n",
        "        if pd.isna(h) or h == '':\n",
        "            return np.nan\n",
        "        if isinstance(h, (int, float)) and not np.isnan(h):\n",
        "            return float(h)\n",
        "        s = str(h)\n",
        "        if '-' in s:\n",
        "            parts = s.split('-')\n",
        "            return int(parts[0]) * 12 + int(parts[1])\n",
        "        return np.nan\n",
        "    dt_2024['Height'] = dt_2024['Height'].apply(_ht_inches)\n",
        "else:\n",
        "    dt_2024['Height'] = pd.to_numeric(dt_2024['Height'], errors='coerce')\n",
        "\n",
        "dt_2024['speed_score'] = np.where(\n",
        "    dt_2024['40yd'].notna() & (dt_2024['40yd'] > 0),\n",
        "    dt_2024['Weight'] * 200 / (dt_2024['40yd'] ** 4),\n",
        "    np.nan\n",
        ")\n",
        "\n",
        "tr_dt = train_df[train_df['Pos'] == 'DT']\n",
        "mean_v = tr_dt['Vertical'].mean()\n",
        "std_v = tr_dt['Vertical'].std()\n",
        "mean_b = tr_dt['Broad Jump'].mean()\n",
        "std_b = tr_dt['Broad Jump'].std()\n",
        "if std_v == 0 or np.isnan(std_v): std_v = 1.0\n",
        "if std_b == 0 or np.isnan(std_b): std_b = 1.0\n",
        "v_z = (dt_2024['Vertical'] - mean_v) / std_v\n",
        "b_z = (dt_2024['Broad Jump'] - mean_b) / std_b\n",
        "has_explosive = dt_2024['Vertical'].notna() | dt_2024['Broad Jump'].notna()\n",
        "dt_2024['explosive_score'] = np.where(has_explosive, v_z.fillna(0) + b_z.fillna(0), np.nan)\n",
        "\n",
        "mean_3 = tr_dt['3Cone'].mean()\n",
        "std_3 = tr_dt['3Cone'].std()\n",
        "mean_sh = tr_dt['Shuttle'].mean()\n",
        "std_sh = tr_dt['Shuttle'].std()\n",
        "if std_3 == 0 or np.isnan(std_3): std_3 = 1.0\n",
        "if std_sh == 0 or np.isnan(std_sh): std_sh = 1.0\n",
        "z_3 = (dt_2024['3Cone'] - mean_3) / std_3\n",
        "z_sh = (dt_2024['Shuttle'] - mean_sh) / std_sh\n",
        "has_agility = dt_2024['3Cone'].notna() | dt_2024['Shuttle'].notna()\n",
        "dt_2024['agility_score'] = np.where(has_agility, (-z_3.fillna(0)) + (-z_sh.fillna(0)), np.nan)\n",
        "\n",
        "def row_to_player_dict(row):\n",
        "    return {\n",
        "        'Height': row['Height'], 'Weight': row['Weight'], '40yd': row['40yd'],\n",
        "        'Vertical': row['Vertical'], 'Broad Jump': row['Broad Jump'],\n",
        "        'Shuttle': row.get('Shuttle', np.nan), '3Cone': row.get('3Cone', np.nan),\n",
        "        'QB_Hurry_final_season': row.get('QB_Hurry_final_season', np.nan),\n",
        "        'TFL_final_season': row.get('TFL_final_season', np.nan),\n",
        "        'Sacks_final_season': row.get('Sacks_final_season', np.nan),\n",
        "        'Sacks_cumulative': row.get('Sacks_cumulative', np.nan),\n",
        "        'TFL_cumulative': row.get('TFL_cumulative', np.nan),\n",
        "        'QB_Hurry_cumulative': row.get('QB_Hurry_cumulative', np.nan),\n",
        "        'speed_score': row['speed_score'], 'explosive_score': row['explosive_score'], 'agility_score': row['agility_score'],\n",
        "        'School': row.get('School', np.nan), 'Year': row.get('Year', 2024),\n",
        "    }\n",
        "\n",
        "predicted_draft_day = []\n",
        "models_used = []\n",
        "for _, row in dt_2024.iterrows():\n",
        "    out = predict_draft(row_to_player_dict(row))\n",
        "    if out['drafted']:\n",
        "        predicted_draft_day.append(f\"Day {out['draft_day']}\")\n",
        "        models_used.append(f\"{out['drafted_model']} + {out['day_model']}\")\n",
        "    else:\n",
        "        predicted_draft_day.append('Undrafted')\n",
        "        models_used.append(out['drafted_model'])\n",
        "\n",
        "dt_2024['predicted_draft_day'] = predicted_draft_day\n",
        "dt_2024['models_used'] = models_used\n",
        "\n",
        "print('2024 drafted DTs: speed_score, explosive_score, agility_score + predicted_draft_day + models_used')\n",
        "print(dt_2024[['Round', 'Pick', 'Player', 'School', 'speed_score', 'explosive_score', 'agility_score', 'predicted_draft_day', 'models_used']].to_string())\n",
        "dt_2024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d7b9aca",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2025 drafted DTs: same analysis as 2024 — speed_score, explosive_score, agility_score + predicted_draft_day\n",
        "\n",
        "dt_2025 = pd.read_csv('dt_drafted_2025.csv')\n",
        "if dt_2025['Height'].dtype == object or (dt_2025['Height'].notna() & (dt_2025['Height'].astype(str).str.contains('-', na=False))).any():\n",
        "    def _ht_inches(h):\n",
        "        if pd.isna(h) or h == '': return np.nan\n",
        "        if isinstance(h, (int, float)) and not np.isnan(h): return float(h)\n",
        "        s = str(h)\n",
        "        if '-' in s: return int(s.split('-')[0]) * 12 + int(s.split('-')[1])\n",
        "        return np.nan\n",
        "    dt_2025['Height'] = dt_2025['Height'].apply(_ht_inches)\n",
        "else:\n",
        "    dt_2025['Height'] = pd.to_numeric(dt_2025['Height'], errors='coerce')\n",
        "\n",
        "dt_2025['speed_score'] = np.where(dt_2025['40yd'].notna() & (dt_2025['40yd'] > 0),\n",
        "    dt_2025['Weight'] * 200 / (dt_2025['40yd'] ** 4), np.nan)\n",
        "\n",
        "tr_dt = train_df[train_df['Pos'] == 'DT']\n",
        "mean_v, std_v = tr_dt['Vertical'].mean(), tr_dt['Vertical'].std()\n",
        "mean_b, std_b = tr_dt['Broad Jump'].mean(), tr_dt['Broad Jump'].std()\n",
        "if std_v == 0 or np.isnan(std_v): std_v = 1.0\n",
        "if std_b == 0 or np.isnan(std_b): std_b = 1.0\n",
        "v_z = (dt_2025['Vertical'] - mean_v) / std_v\n",
        "b_z = (dt_2025['Broad Jump'] - mean_b) / std_b\n",
        "has_explosive = dt_2025['Vertical'].notna() | dt_2025['Broad Jump'].notna()\n",
        "dt_2025['explosive_score'] = np.where(has_explosive, v_z.fillna(0) + b_z.fillna(0), np.nan)\n",
        "\n",
        "mean_3, std_3 = tr_dt['3Cone'].mean(), tr_dt['3Cone'].std()\n",
        "mean_sh, std_sh = tr_dt['Shuttle'].mean(), tr_dt['Shuttle'].std()\n",
        "if std_3 == 0 or np.isnan(std_3): std_3 = 1.0\n",
        "if std_sh == 0 or np.isnan(std_sh): std_sh = 1.0\n",
        "z_3 = (dt_2025['3Cone'] - mean_3) / std_3\n",
        "z_sh = (dt_2025['Shuttle'] - mean_sh) / std_sh\n",
        "has_agility = dt_2025['3Cone'].notna() | dt_2025['Shuttle'].notna()\n",
        "dt_2025['agility_score'] = np.where(has_agility, (-z_3.fillna(0)) + (-z_sh.fillna(0)), np.nan)\n",
        "\n",
        "def row_to_player_dict_2025(row):\n",
        "    return {\n",
        "        'Height': row['Height'], 'Weight': row['Weight'], '40yd': row['40yd'],\n",
        "        'Vertical': row['Vertical'], 'Broad Jump': row['Broad Jump'],\n",
        "        'Shuttle': row.get('Shuttle', np.nan), '3Cone': row.get('3Cone', np.nan),\n",
        "        'QB_Hurry_final_season': row.get('QB_Hurry_final_season', np.nan),\n",
        "        'TFL_final_season': row.get('TFL_final_season', np.nan),\n",
        "        'Sacks_final_season': row.get('Sacks_final_season', np.nan),\n",
        "        'Sacks_cumulative': row.get('Sacks_cumulative', np.nan),\n",
        "        'TFL_cumulative': row.get('TFL_cumulative', np.nan),\n",
        "        'QB_Hurry_cumulative': row.get('QB_Hurry_cumulative', np.nan),\n",
        "        'speed_score': row['speed_score'], 'explosive_score': row['explosive_score'], 'agility_score': row['agility_score'],\n",
        "        'School': row.get('School', np.nan), 'Year': row.get('Year', 2025),\n",
        "    }\n",
        "\n",
        "predicted_draft_day_2025 = []\n",
        "models_used_2025 = []\n",
        "for _, row in dt_2025.iterrows():\n",
        "    out = predict_draft(row_to_player_dict_2025(row))\n",
        "    if out['drafted']:\n",
        "        predicted_draft_day_2025.append(f\"Day {out['draft_day']}\")\n",
        "        models_used_2025.append(f\"{out['drafted_model']} + {out['day_model']}\")\n",
        "    else:\n",
        "        predicted_draft_day_2025.append('Undrafted')\n",
        "        models_used_2025.append(out['drafted_model'])\n",
        "\n",
        "dt_2025['predicted_draft_day'] = predicted_draft_day_2025\n",
        "dt_2025['models_used'] = models_used_2025\n",
        "\n",
        "print('2025 drafted DTs: speed_score, explosive_score, agility_score + predicted_draft_day + models_used')\n",
        "print(dt_2025[['Round', 'Pick', 'Player', 'School', 'speed_score', 'explosive_score', 'agility_score', 'predicted_draft_day', 'models_used']].to_string())\n",
        "dt_2025"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a49ad2c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2026 drafted DTs: same analysis as 2024/2025 — speed_score, explosive_score, agility_score + predicted_draft_day\n",
        "\n",
        "dt_2026 = pd.read_csv('dt_drafted_2026.csv')\n",
        "if dt_2026['Height'].dtype == object or (dt_2026['Height'].notna() & (dt_2026['Height'].astype(str).str.contains('-', na=False))).any():\n",
        "    def _ht_inches(h):\n",
        "        if pd.isna(h) or h == '': return np.nan\n",
        "        if isinstance(h, (int, float)) and not np.isnan(h): return float(h)\n",
        "        s = str(h)\n",
        "        if '-' in s: return int(s.split('-')[0]) * 12 + int(s.split('-')[1])\n",
        "        return np.nan\n",
        "    dt_2026['Height'] = dt_2026['Height'].apply(_ht_inches)\n",
        "else:\n",
        "    dt_2026['Height'] = pd.to_numeric(dt_2026['Height'], errors='coerce')\n",
        "\n",
        "dt_2026['speed_score'] = np.where(dt_2026['40yd'].notna() & (dt_2026['40yd'] > 0),\n",
        "    dt_2026['Weight'] * 200 / (dt_2026['40yd'] ** 4), np.nan)\n",
        "\n",
        "tr_dt = train_df[train_df['Pos'] == 'DT']\n",
        "mean_v, std_v = tr_dt['Vertical'].mean(), tr_dt['Vertical'].std()\n",
        "mean_b, std_b = tr_dt['Broad Jump'].mean(), tr_dt['Broad Jump'].std()\n",
        "if std_v == 0 or np.isnan(std_v): std_v = 1.0\n",
        "if std_b == 0 or np.isnan(std_b): std_b = 1.0\n",
        "v_z = (dt_2026['Vertical'] - mean_v) / std_v\n",
        "b_z = (dt_2026['Broad Jump'] - mean_b) / std_b\n",
        "has_explosive = dt_2026['Vertical'].notna() | dt_2026['Broad Jump'].notna()\n",
        "dt_2026['explosive_score'] = np.where(has_explosive, v_z.fillna(0) + b_z.fillna(0), np.nan)\n",
        "\n",
        "mean_3, std_3 = tr_dt['3Cone'].mean(), tr_dt['3Cone'].std()\n",
        "mean_sh, std_sh = tr_dt['Shuttle'].mean(), tr_dt['Shuttle'].std()\n",
        "if std_3 == 0 or np.isnan(std_3): std_3 = 1.0\n",
        "if std_sh == 0 or np.isnan(std_sh): std_sh = 1.0\n",
        "z_3 = (dt_2026['3Cone'] - mean_3) / std_3\n",
        "z_sh = (dt_2026['Shuttle'] - mean_sh) / std_sh\n",
        "has_agility = dt_2026['3Cone'].notna() | dt_2026['Shuttle'].notna()\n",
        "dt_2026['agility_score'] = np.where(has_agility, (-z_3.fillna(0)) + (-z_sh.fillna(0)), np.nan)\n",
        "\n",
        "def row_to_player_dict_2026(row):\n",
        "    return {\n",
        "        'Height': row['Height'], 'Weight': row['Weight'], '40yd': row['40yd'],\n",
        "        'Vertical': row['Vertical'], 'Broad Jump': row['Broad Jump'],\n",
        "        'Shuttle': row.get('Shuttle', np.nan), '3Cone': row.get('3Cone', np.nan),\n",
        "        'QB_Hurry_final_season': row.get('QB_Hurry_final_season', np.nan),\n",
        "        'TFL_final_season': row.get('TFL_final_season', np.nan),\n",
        "        'Sacks_final_season': row.get('Sacks_final_season', np.nan),\n",
        "        'Sacks_cumulative': row.get('Sacks_cumulative', np.nan),\n",
        "        'TFL_cumulative': row.get('TFL_cumulative', np.nan),\n",
        "        'QB_Hurry_cumulative': row.get('QB_Hurry_cumulative', np.nan),\n",
        "        'speed_score': row['speed_score'], 'explosive_score': row['explosive_score'], 'agility_score': row['agility_score'],\n",
        "        'School': row.get('School', np.nan), 'Year': row.get('Year', 2026),\n",
        "    }\n",
        "\n",
        "predicted_draft_day_2026 = []\n",
        "models_used_2026 = []\n",
        "for _, row in dt_2026.iterrows():\n",
        "    out = predict_draft(row_to_player_dict_2026(row))\n",
        "    if out['drafted']:\n",
        "        predicted_draft_day_2026.append(f\"Day {out['draft_day']}\")\n",
        "        models_used_2026.append(f\"{out['drafted_model']} + {out['day_model']}\")\n",
        "    else:\n",
        "        predicted_draft_day_2026.append('Undrafted')\n",
        "        models_used_2026.append(out['drafted_model'])\n",
        "\n",
        "dt_2026['predicted_draft_day'] = predicted_draft_day_2026\n",
        "dt_2026['models_used'] = models_used_2026\n",
        "\n",
        "print('2026 drafted DTs: speed_score, explosive_score, agility_score + predicted_draft_day + models_used')\n",
        "print(dt_2026[['Round', 'Pick', 'Player', 'School', 'speed_score', 'explosive_score', 'agility_score', 'predicted_draft_day', 'models_used']].to_string())\n",
        "dt_2026"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
